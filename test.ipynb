{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inited stanford CoreNLP client, dont forget to close it!\n"
     ]
    }
   ],
   "source": [
    "import preprocess as pp\n",
    "import configs\n",
    "import persister\n",
    "import relation\n",
    "import lda\n",
    "import json\n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档向量化测试\n",
    "# count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Many existing knowledge bases(KBs), including Freebase, Yago, and NELL, rely on a ﬁxed ontology, given as an input to the system, which deﬁnes the data to be cataloged in the KB, i.e., a hierarchy of categories and relations between them. The system then extracts facts that match the predeﬁned ontology. We propose an unsupervised model that jointly learns a latent ontological structure of an input corpus, and identiﬁes facts from the corpus that match the learned structure. Our approach combines mixed membership stochastic block models and topic models to infer a structure by jointly modeling text, a latent concept hierarchy, and latent semantic relationships among the entities mentioned in the text. As a case study, we apply the model to a corpus of Web documents from the software domain,and evaluate the accuracy of the various components of the learned ontology. \"\n",
    "b = [\"hello world. what the fuck.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\" \".join(preprocess(a))]\n",
    "vector = CountVectorizer(ngram_range=(1, 2), vocabulary=[\"knowledge base\"], stop_words='english')\n",
    "vector.build_analyzer()\n",
    "x = vector.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = CountVectorizer(ngram_range=(1, 2), vocabulary=['fuck', 'hello', 'world', \"hello world\"], stop_words='english')\n",
    "estimator.build_analyzer()\n",
    "res = estimator.fit_transform(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.toarray()\n",
    "# estimator.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斯坦福nlp工具测试\n",
    "# stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('/mnt/d/stanford-corenlp-full-2018-02-27', port=9000)\n",
    "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'\n",
    "print('Tokenize:', nlp.word_tokenize(sentence))\n",
    "print('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print('Named Entities:', nlp.ner(sentence))\n",
    "print('Constituency Parsing:', nlp.parse(sentence))\n",
    "print('Dependency Parsing:', nlp.dependency_parse(sentence))\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 官方corenlp api\n",
    "# stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新闻数据集测试\n",
    "# 20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newsgroups\n",
    "size = 500\n",
    "tmp = newsgroups.get_news_data(size)\n",
    "newsdata = []\n",
    "for cate in tmp:\n",
    "    newsdata.extend(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [' '.join(pp.preprocess_abstract(a)) for a in tmp]\n",
    "persister.save_json(configs.NEWSDATA, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理成句子\n",
    "# nltk.sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newssent = []\n",
    "for news in newsdata:\n",
    "    newssent.append(pp.split2sent(news))\n",
    "persister.save_json(configs.NEWSSENT, newssent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newssenttoken = []\n",
    "for news in newssent:\n",
    "    tokenized_lemmatized_news = []\n",
    "    for sent in news:\n",
    "        tokenized_lemmatized_news.append(relation.lemmatize_sent_words(sent))\n",
    "    newssenttoken.append(tokenized_lemmatized_news)\n",
    "persister.save_json(configs.NEWSSENTTOKEN, newssenttoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprossed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = persister.load_json(configs.NEWSDATA)\n",
    "newssent = persister.load_json(configs.NEWSSENT)\n",
    "newssenttoken = persister.load_json(configs.NEWSSENTTOKEN)\n",
    "newsparse = []\n",
    "with open(configs.NEWSPARSE+\".json\", encoding=\"utf8\") as f:\n",
    "    for l in f:\n",
    "        newsparse.append(json.loads(l))\n",
    "# newsparse = [json.loads(n) for n in newsparse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 --------------------\n",
      "window:894.4808085018936\n",
      "file:844.5471131576066\n",
      "image:804.220378687271\n",
      "edu:771.5948685567065\n",
      "graphic:586.0353569857319\n",
      "program:548.6607874729475\n",
      "use:548.6318542418962\n",
      "server:489.24702551143844\n",
      "available:488.56592120409255\n",
      "display:447.98498605836124\n",
      "widget:443.4712499791329\n",
      "color:440.59927142836364\n",
      "version:427.81261984287903\n",
      "ha:413.4416084120781\n",
      "application:411.2118730873431\n",
      "using:390.23014165406516\n",
      "com:377.30116401940575\n",
      "motif:372.2449224762105\n",
      "software:354.63735327422484\n",
      "like:349.4803320270371\n",
      "432:0.9998665847832521\n",
      "160:0.9998441846371635\n",
      "553:0.9998407473574282\n",
      "395:0.9998369519682108\n",
      "554:0.9998203062696561\n",
      "60:0.9998115500043383\n",
      "898:0.9998085433197132\n",
      "847:0.9997970536840844\n",
      "888:0.9997939325026625\n",
      "520:0.9996388611461496\n",
      "964:0.9995901641853403\n",
      "218:0.9991375211000731\n",
      "74:0.9983236847937171\n",
      "55:0.9982480974139522\n",
      "92:0.9982266134927563\n",
      "967:0.9979275746598496\n",
      "951:0.9974895529352918\n",
      "154:0.9971017660445043\n",
      "851:0.996842875514367\n",
      "442:0.9965308830150026\n",
      "# 2 --------------------\n",
      "wa:735.2059813322505\n",
      "year:643.911459684747\n",
      "edu:601.8205080506607\n",
      "writes:481.88561973689576\n",
      "game:461.3801035849513\n",
      "ha:406.79049758964356\n",
      "article:393.434919525684\n",
      "team:343.1010831529144\n",
      "think:319.272427759557\n",
      "run:306.28506345140306\n",
      "good:305.06412168800296\n",
      "like:282.591469722469\n",
      "player:265.4417181809311\n",
      "time:261.4440941413067\n",
      "better:232.8695262216275\n",
      "baseball:214.99188885952856\n",
      "know:211.10615035026234\n",
      "hit:197.5436710313403\n",
      "com:188.9093974287414\n",
      "win:182.84503191010563\n",
      "1757:0.9988545287840931\n",
      "1533:0.998283392022404\n",
      "1538:0.998244995375903\n",
      "1552:0.9981614069821371\n",
      "1750:0.9981349165898763\n",
      "1925:0.9981166344586501\n",
      "1628:0.9981104571056733\n",
      "1569:0.9979238740719427\n",
      "1555:0.9978888380196765\n",
      "1664:0.9977218427395301\n",
      "1923:0.9976152909390151\n",
      "1521:0.9975370895823495\n",
      "1927:0.9973335056926997\n",
      "1772:0.9969904991729674\n",
      "1586:0.9969605351320903\n",
      "1519:0.9968990915592693\n",
      "1893:0.9968275127758154\n",
      "1680:0.996805455309443\n",
      "1966:0.9968007248384302\n",
      "1724:0.9966999589438047\n",
      "# 3 --------------------\n",
      "entry:508.240057434343\n",
      "file:404.9416639214129\n",
      "output:352.0004707655644\n",
      "program:269.82676092515965\n",
      "line:185.51567571708628\n",
      "build:154.5118122840976\n",
      "rule:153.72344860592608\n",
      "section:152.5058343307177\n",
      "printf:141.24817592779058\n",
      "char:140.7010361326993\n",
      "oname:136.24999992560637\n",
      "eof:135.20349403412854\n",
      "info:131.3295844827251\n",
      "int:129.7092695692438\n",
      "ok:128.55074383707733\n",
      "request:124.44340654670015\n",
      "remark:124.04115996218775\n",
      "check:120.62623713592933\n",
      "stream:120.1308266725835\n",
      "contest:116.48602492752875\n",
      "998:0.9997962629974592\n",
      "785:0.9997913682530282\n",
      "612:0.9997314442533343\n",
      "735:0.9997249759559589\n",
      "144:0.991176418478924\n",
      "619:0.9606620778663714\n",
      "782:0.958884321651587\n",
      "732:0.939691887363302\n",
      "140:0.9318826755327779\n",
      "700:0.8749773416092983\n",
      "387:0.848509099037564\n",
      "1924:0.7499559215859788\n",
      "655:0.74336574408713\n",
      "984:0.7309016254618634\n",
      "1114:0.7212126615247983\n",
      "1291:0.6984042412193543\n",
      "966:0.6757605147033993\n",
      "82:0.6582557950949444\n",
      "467:0.6472731526731451\n",
      "289:0.6244860408957761\n",
      "# 4 --------------------\n",
      "car:950.3249308061329\n",
      "writes:502.30016077289747\n",
      "article:473.1119137059413\n",
      "wa:432.11118671078526\n",
      "com:423.3220319316498\n",
      "edu:406.1398051477658\n",
      "like:281.60584087001746\n",
      "ha:223.02843201684482\n",
      "apr:209.19909353506966\n",
      "know:197.8740401413088\n",
      "engine:191.3872899764667\n",
      "time:184.8932378392284\n",
      "think:166.6527346319245\n",
      "good:158.1894680193873\n",
      "right:149.9994200649368\n",
      "problem:143.0797041351912\n",
      "speed:141.81018227823003\n",
      "auto:135.03794270384222\n",
      "really:133.61918814004883\n",
      "doe:133.0601717871429\n",
      "1261:0.9976050891786289\n",
      "1195:0.99749682231933\n",
      "1062:0.9974219501363677\n",
      "1018:0.997239209210985\n",
      "1134:0.9971784023057464\n",
      "1200:0.9966121469626039\n",
      "1229:0.9965001875787824\n",
      "1130:0.9964432445911182\n",
      "1151:0.9963894641016816\n",
      "1358:0.996308655013316\n",
      "1245:0.9962856035332065\n",
      "1382:0.9959285405557018\n",
      "1227:0.9959208349347433\n",
      "1320:0.9958007119843796\n",
      "1400:0.9957520777035751\n",
      "1423:0.9957088118912075\n",
      "1402:0.995696944164052\n",
      "1175:0.9956846493108708\n",
      "1469:0.9955970838054253\n",
      "1325:0.9954233990209909\n"
     ]
    }
   ],
   "source": [
    "# load lda res\n",
    "terms, doc_topic, topic_word = persister.read_lda(configs.NEWSLDA)\n",
    "lda.print_topics(topic_word, terms, doc_topic)\n",
    "top_terms, top_docs = lda.get_topics(topic_word, terms, doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "It has a sensor for the brake pedal, just like other CCs, but does NOT have a sensor for the clutch pedal.\n",
      "['It', 'ha', 'a', 'sensor', 'for', 'the', 'brake', 'pedal', ',', 'just', 'like', 'other', 'CCs', ',', 'but', 'doe', 'NOT', 'have', 'a', 'sensor', 'for', 'the', 'clutch', 'pedal', '.']\n",
      "howdy little new newsgroup would like tap knowledge expertise available subject market cruise control background recently broke ankle road bicycling accident place five screw yuk two week returning texas home school byu provo utah imagine trying drive nearly mile broken right ankle epitome good time car doe cruise control would pedalling ha ha messed ankle question general opinion market cruise control unit realize cheap cc cruise control say pep boy going good factory professionally installed unit thing uderstand probably expect much way accuracy look sort thing anything got ta better trying drive hosed ankle jeep cherokee speed standard l engine kettering sp ignition know distributor cap rotor set electronic maybe could guessed trying give information completly found cc unit buck seems use vehicle vacuum system instead electric servor motor good bad buy cc vacuum hose tap ha two speed sensor one magnetic one get signal negative side distributor kinda like tach pick understand use either one best manual say read store today magnetic axle set accurate harder install really big difference ha sensor brake pedal like cc doe sensor clutch pedal paying real close attention might push clutch cruise trying get speed would wind engine kinda high got wit turned thing pretty coordinated bother girlfriend car would bother ok installation also call attachment steady brake signal switched brake signal think get switched brake signal correct side brake light blade fuse right sure get steady brake signal matter exactly idea manufaturer want get think figure thing like hook negative side tach type sensing gizmo cabin control unit ground miscellaneous business need little help worth money safety risk device particularly good market cc professionally installed cc signifacantly better worth cabbage unit saw sorry manufacturer model number pep boy sufficient simple need get thing installed properly specifically question father built veep volkswagen powered jeep cj wa high school consider fairly good tool electronics car installation scare want certain get thing installed correctly cherokee wee bit complicated veep appreciate time reading post would appreciate expertise opinion anybody ha subject would like share wisdom please email get group often check mail time thanks help anyone may\n"
     ]
    }
   ],
   "source": [
    "idx_news = 1195\n",
    "idx_sent = 21\n",
    "print(len(newssent[idx_news]))\n",
    "print(newssent[idx_news][idx_sent])\n",
    "print(newssenttoken[idx_news][idx_sent])\n",
    "print(texts[idx_news])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "dict_keys(['index', 'parse', 'basicDependencies', 'enhancedDependencies', 'enhancedPlusPlusDependencies', 'tokens'])\n"
     ]
    }
   ],
   "source": [
    "print(len(newsparse[idx_news][\"sentences\"]))\n",
    "print(newsparse[idx_news][\"sentences\"][idx_sent].keys())\n",
    "examparse = newsparse[idx_news][\"sentences\"][idx_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (S\n",
      "      (NP (PRP It))\n",
      "      (VP (VBZ has)\n",
      "        (NP (DT a) (NN sensor))\n",
      "        (PP\n",
      "          (PP (IN for)\n",
      "            (NP (DT the) (NNP brake) (NN pedal)))\n",
      "          (, ,) (RB just)\n",
      "          (PP (IN like)\n",
      "            (NP (JJ other) (NNS CCs))))))\n",
      "    (, ,)\n",
      "    (CC but)\n",
      "    (SQ (VBZ does)\n",
      "      (NP (NNP NOT))\n",
      "      (VP (VB have)\n",
      "        (NP\n",
      "          (NP (DT a) (NN sensor))\n",
      "          (PP (IN for)\n",
      "            (NP (DT the) (NN clutch) (NN pedal))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "print(examparse[\"parse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'writes', 'article', 'wa', 'com', 'edu', 'like', 'ha', 'apr', 'know', 'engine', 'time', 'think', 'good', 'right', 'problem', 'speed', 'auto', 'really', 'doe']\n"
     ]
    }
   ],
   "source": [
    "t4 = [t[0] for t in top_terms[3]]\n",
    "print(t4)\n",
    "idxs, count = relation.extract_important_sents(newssenttoken[idx_news], t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\n",
      "  (S\n",
      "    (S\n",
      "      (NP (PRP It))\n",
      "      (VP (VBZ has)\n",
      "        (NP (DT a) (NN sensor))\n",
      "        (PP\n",
      "          (PP (IN for)\n",
      "            (NP (DT the) (NNP brake) (NN pedal)))\n",
      "          (, ,) (RB just)\n",
      "          (PP (IN like)\n",
      "            (NP (JJ other) (NNS CCs))))))\n",
      "    (, ,)\n",
      "    (CC but)\n",
      "    (SQ (VBZ does)\n",
      "      (NP (NNP NOT))\n",
      "      (VP (VB have)\n",
      "        (NP\n",
      "          (NP (DT a) (NN sensor))\n",
      "          (PP (IN for)\n",
      "            (NP (DT the) (NN clutch) (NN pedal))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "cparse = relation.CLI.parse(newssent[idx_news][idx_sent])\n",
    "print(cparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       ROOT                                                                  \n",
      "                                                                        |                                                                     \n",
      "                                                                        S                                                                    \n",
      "                   _____________________________________________________|__________________________________________________________________   \n",
      "                  S                                                          |   |        SQ                                               | \n",
      "  ________________|__________________                                        |   |    ____|________                                        |  \n",
      " |                                   VP                                      |   |   |    |        VP                                      | \n",
      " |    _______________________________|__________                             |   |   |    |    ____|______________                         |  \n",
      " |   |       |                                  PP                           |   |   |    |   |                   NP                       | \n",
      " |   |       |                   _______________|______________              |   |   |    |   |         __________|_______                 |  \n",
      " |   |       |                  PP              |   |          PP            |   |   |    |   |        |                  PP               | \n",
      " |   |       |           _______|____           |   |     _____|____         |   |   |    |   |        |           _______|____            |  \n",
      " NP  |       NP         |            NP         |   |    |          NP       |   |   |    NP  |        NP         |            NP          | \n",
      " |   |    ___|____      |    ________|_____     |   |    |      ____|___     |   |   |    |   |     ___|____      |    ________|______     |  \n",
      "PRP VBZ  DT       NN    IN  DT      NNP    NN   ,   RB   IN    JJ      NNS   ,   CC VBZ  NNP  VB   DT       NN    IN  DT       NN     NN   . \n",
      " |   |   |        |     |   |        |     |    |   |    |     |        |    |   |   |    |   |    |        |     |   |        |      |    |  \n",
      " It has  a      sensor for the     brake pedal  ,  just like other     CCs   ,  but does NOT have  a      sensor for the     clutch pedal  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = Tree.fromstring(cparse)\n",
    "t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"exampleres.json\",encoding=\"utf8\")as f:\n",
    "    res = json.load(f)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda362",
   "language": "python",
   "name": "lda362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
