{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not use stanford CoreNLP client!\n"
     ]
    }
   ],
   "source": [
    "import preprocess as pp\n",
    "import configs\n",
    "import persister\n",
    "import relation\n",
    "import lda\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tree import Tree\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文档向量化测试\n",
    "# count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Many existing knowledge bases(KBs), including Freebase, Yago, and NELL, rely on a ﬁxed ontology, given as an input to the system, which deﬁnes the data to be cataloged in the KB, i.e., a hierarchy of categories and relations between them. The system then extracts facts that match the predeﬁned ontology. We propose an unsupervised model that jointly learns a latent ontological structure of an input corpus, and identiﬁes facts from the corpus that match the learned structure. Our approach combines mixed membership stochastic block models and topic models to infer a structure by jointly modeling text, a latent concept hierarchy, and latent semantic relationships among the entities mentioned in the text. As a case study, we apply the model to a corpus of Web documents from the software domain,and evaluate the accuracy of the various components of the learned ontology. \"\n",
    "b = [\"hello world. what the fuck.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [\" \".join(preprocess(a))]\n",
    "vector = CountVectorizer(ngram_range=(1, 2), vocabulary=[\"knowledge base\"], stop_words='english')\n",
    "vector.build_analyzer()\n",
    "x = vector.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = CountVectorizer(ngram_range=(1, 2), vocabulary=['fuck', 'hello', 'world', \"hello world\"], stop_words='english')\n",
    "estimator.build_analyzer()\n",
    "res = estimator.fit_transform(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.toarray()\n",
    "# estimator.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斯坦福nlp工具测试\n",
    "# stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('/mnt/d/stanford-corenlp-full-2018-02-27', port=9000)\n",
    "sentence = 'Brink is taking part in the final exercise.'\n",
    "print('Tokenize:', nlp.word_tokenize(sentence))\n",
    "print('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print('Named Entities:', nlp.ner(sentence))\n",
    "print('Constituency Parsing:', nlp.parse(sentence))\n",
    "print('Dependency Parsing:', nlp.dependency_parse(sentence))\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 官方corenlp api\n",
    "# stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新闻数据集测试\n",
    "# 20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newsgroups\n",
    "size = 500\n",
    "tmp = newsgroups.get_news_data(size)\n",
    "newsdata = []\n",
    "for cate in tmp:\n",
    "    newsdata.extend(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In regards to fractal commpression , I have seen 2 fractal compressed \" movies \" .\n",
      "They were both fairly impressive .\n",
      "The first one was a 64 gray scale \" movie \" of Casablanca , it was 1.3 MB and had 11 minutes of 13 fps video .\n",
      "It was a little grainy but not bad at all .\n",
      "The second one I saw was only 3 minutes but it had 8 bit color with 10 fps and measured in at 1.2 MB .\n",
      "I consider the fractal movies a practical thing to explore .\n",
      "But unlike many other formats out there , you do end up losing resolution .\n",
      "I do n't know what kind of software/hardware was used for creating the \" movies \" I saw but the guy that showed them to me said it took 5-15 minutes per frame to generate .\n",
      "But as I said above playback was 10 or more frames per second .\n",
      "And how else could you put 11 minutes on one floppy disk ?\n"
     ]
    }
   ],
   "source": [
    "for i in [\" \".join([w[\"originalText\"] for w in sent[\"tokens\"]]) for sent in res[\"sentences\"]]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting server defaults from: ./corenlp_server.props\n",
      "Starting server with command: java -Xmx5G -cp /mnt/d/stanford-corenlp-full-2018-02-27/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 30000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties ./corenlp_server.props -preload pos,parse,depparse,lemma\n"
     ]
    }
   ],
   "source": [
    "from stanza.server import CoreNLPClient\n",
    "with CoreNLPClient(properties=\"./corenlp_server.props\", timeout=30000, memory='5G') as client:\n",
    "    res = relation.corenlp_annotate(client, pp.format_news(newsdata[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [' '.join(pp.preprocess_abstract(a))\n",
    "persister.save_json(configs.NEWSDATA, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理成句子\n",
    "# nltk.sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newssent = []\n",
    "for news in newsdata:\n",
    "    newssent.append(pp.split2sent(news))\n",
    "persister.save_json(configs.NEWSSENT, newssent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newssenttoken = []\n",
    "for news in newssent:\n",
    "    tokenized_lemmatized_news = []\n",
    "    for sent in news:\n",
    "        tokenized_lemmatized_news.append(relation.lemmatize_sent_words(sent))\n",
    "    newssenttoken.append(tokenized_lemmatized_news)\n",
    "persister.save_json(configs.NEWSSENTTOKEN, newssenttoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprossed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawnews = persister.load_json(configs.RAWNEWS)\n",
    "newsparse = persister.read_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have posted a DOS MPEG decoder/player to alt.binaries.pictures.utilities.\n",
      "\n",
      "Here is a short description and some technical information, taken from the\n",
      "accompanying documentation:\n",
      "\n",
      "\n",
      "                              DMPEG V1.0\n",
      "\n",
      "                       Public Domain MPEG decoder\n",
      "\n",
      "                           by Stefan Eckart\n",
      "\n",
      "\n",
      "0. Features\n",
      "===========\n",
      "\n",
      "DMPEG/DMPLAY is another MPEG decoder/player for the PC:\n",
      "\n",
      "\n",
      " - decodes (nearly) the full MPEG video standard\n",
      "   (I,P,B frames, frame size up to at least 352x240 supported)\n",
      "\n",
      " - saves decoded sequence in 8 or 24bit raw file for later display\n",
      "\n",
      " - optional on-screen display during decoding (requires VGA)\n",
      "\n",
      " - several dithering options: ordered dither, Floyd-Steinberg, grayscale\n",
      "\n",
      " - color-space selection\n",
      "\n",
      " - runs under DOS, 640KB RAM, no MS-Windows required\n",
      "\n",
      " - very compact (small code / small data models, 16 bit arithmetic)\n",
      "\n",
      " - real time display of the raw file by a separate player for\n",
      "   VGA and many Super-VGAs\n",
      "\n",
      "...\n",
      "\n",
      "4. Technical information\n",
      "========================\n",
      "\n",
      "The player is a rather straightforward implementation of the MPEG spec [1].\n",
      "The IDCT is based on the Chen-Wang 13 multiplication algorithm [2]\n",
      "(not quite the optimum, I know). Blocks with not more than eight non-zero\n",
      "coefficients use a non-separated direct multiply-accumulate 2D-IDCT\n",
      "(sounds great, doesn't it?), which turned out to be faster than a 'fast'\n",
      "algorithm in this (quite common) case. Dithering is pretty standard. Main\n",
      "difference to the Berkeley decoder (except for the fewer number of supported\n",
      "algorithms) is the use of 256 instead of 128 colors, the (default) option to\n",
      "use a restricted color-space and the implementation of a color saturation\n",
      "dominant ordered dither. This leads to a significantly superior quality of\n",
      "the dithered image (I claim, judge yourself).\n",
      "\n",
      "Restricted color-space means that the U and V components are clipped to\n",
      "+/-0.25 (instead of +/-0.5) and the display color-space points are distributed\n",
      "over this restricted space. Since the distance between color-space points\n",
      "is thus reduced by a factor of two, the color resolution is doubled at the\n",
      "expense of not being able to represent fully saturated colors.\n",
      "\n",
      "Saturation dominant ordered dither is a method by which a color, lying\n",
      "somewhere between the points of the display color space, is approximated\n",
      "by primarily alternating between two points of constant hue instead of\n",
      "constant saturation. This yields subjectivly better quality due to the\n",
      "lower sensitivity of the human viewing system to saturation changes than\n",
      "to hue changes (the same reasoning as used by the PAL TV standard to improve\n",
      "on NTSC). The improvement is particularly visible in dark brown or redish\n",
      "areas.\n",
      "\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rawnews[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'news_lda.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-af8b5fa88bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load lda res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersister\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEWSLDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/e/毕业论文_ued/code/persister.py\u001b[0m in \u001b[0;36mread_lda\u001b[0;34m(npz_name)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mnpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"terms\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc_topic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"topic_word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/e/毕业论文_ued/code/persister.py\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(npz_name)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lda362/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'news_lda.npz'"
     ]
    }
   ],
   "source": [
    "# load lda res\n",
    "terms, doc_topic, topic_word = persister.read_lda(configs.NEWSLDA)\n",
    "lda.print_topics(topic_word, terms, doc_topic)\n",
    "top_terms, top_docs = lda.get_topics(topic_word, terms, doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_news = 1195\n",
    "idx_sent = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have posted a DOS MPEG decoder/player to alt.binaries.pictures.utilities.\\n\\nHere is a short description and some technical information, taken from the\\naccompanying documentation:\\n\\n\\n                              DMPEG V1.0\\n\\n                       Public Domain MPEG decoder\\n\\n                           by Stefan Eckart\\n\\n\\n0. Features\\n===========\\n\\nDMPEG/DMPLAY is another MPEG decoder/player for the PC:\\n\\n\\n - decodes (nearly) the full MPEG video standard\\n   (I,P,B frames, frame size up to at least 352x240 supported)\\n\\n - saves decoded sequence in 8 or 24bit raw file for later display\\n\\n - optional on-screen display during decoding (requires VGA)\\n\\n - several dithering options: ordered dither, Floyd-Steinberg, grayscale\\n\\n - color-space selection\\n\\n - runs under DOS, 640KB RAM, no MS-Windows required\\n\\n - very compact (small code / small data models, 16 bit arithmetic)\\n\\n - real time display of the raw file by a separate player for\\n   VGA and many Super-VGAs\\n\\n...\\n\\n4. Technical information\\n========================\\n\\nThe player is a rather straightforward implementation of the MPEG spec [1].\\nThe IDCT is based on the Chen-Wang 13 multiplication algorithm [2]\\n(not quite the optimum, I know). Blocks with not more than eight non-zero\\ncoefficients use a non-separated direct multiply-accumulate 2D-IDCT\\n(sounds great, doesn't it?), which turned out to be faster than a 'fast'\\nalgorithm in this (quite common) case. Dithering is pretty standard. Main\\ndifference to the Berkeley decoder (except for the fewer number of supported\\nalgorithms) is the use of 256 instead of 128 colors, the (default) option to\\nuse a restricted color-space and the implementation of a color saturation\\ndominant ordered dither. This leads to a significantly superior quality of\\nthe dithered image (I claim, judge yourself).\\n\\nRestricted color-space means that the U and V components are clipped to\\n+/-0.25 (instead of +/-0.5) and the display color-space points are distributed\\nover this restricted space. Since the distance between color-space points\\nis thus reduced by a factor of two, the color resolution is doubled at the\\nexpense of not being able to represent fully saturated colors.\\n\\nSaturation dominant ordered dither is a method by which a color, lying\\nsomewhere between the points of the display color space, is approximated\\nby primarily alternating between two points of constant hue instead of\\nconstant saturation. This yields subjectivly better quality due to the\\nlower sensitivity of the human viewing system to saturation changes than\\nto hue changes (the same reasoning as used by the PAL TV standard to improve\\non NTSC). The improvement is particularly visible in dark brown or redish\\nareas.\\n\\n...\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawnews[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in <smn42b1w165w@cybernet.cse.fau.edu> vlasis@cybernet.cse.fau.edu -lrb- vlasis theodore -rrb- write : > tobias@convex.com -lrb- Allen Tobias -rrb- write : >> in article <1993apr15.024246.8076@virginia.edu> ejv2j@virginia.edu -lrb- `` Erik Vel >> > this happen about a year ago on the Washington DC Beltway .',\n",
       " '>> > snot nosed drunken kid decide it would be really cool to >> > throw huge rock down on car from a overpass .',\n",
       " 'four or five >> > car be hit .',\n",
       " 'there be several serious injury , and sadly >> > a small girl sit in the front seat of one of they be strike >> > in the head by one of the larger rock .',\n",
       " 'I do not recall if she >> > make it , but I think she be comatose for a month or so and >> > doctor be not hold out hope that she would live .',\n",
       " '>> > >> > what the hell be happen to this great country of ours ?',\n",
       " 'I >> > can see boyhood prank of pee off of bridge and such , but >> > 20 pound rock ??!',\n",
       " 'have we society really stoop this low ??',\n",
       " '>> > >> > Erik velapold >> >> Society , as we have know it , it come apart at the seam !',\n",
       " \"the basic reason >> be that human life have be devalue to the point be kill someone be >> `` no Big Deal '' .\",\n",
       " \"Kid 's see hundred on murderous act on tv , we can abort >> child on demand , and kill the sick and old at will .\",\n",
       " 'so why be surprise >> when some kid drop 20 lb rock and kill people .',\n",
       " \"they do not care because the >> message they hear be `` Life be cheap '' !\",\n",
       " '>> >> at > well people fortunatly or unfortunatly , > only the US be experience the devaluation of human life -lrb- among > develop nation -rrb- . >',\n",
       " 'I be a american but I be raise in Europe , where the worst thing that > can happen to somebody be get he car break into , or have he pocket > pick by slave or russian refugee . >',\n",
       " 'of cource there will be some nutcase , but that extremely rare . >',\n",
       " 'i.e. in Greece you can walk through any neighborhood at any time during > the night without even worry . >',\n",
       " 'in Germany , you can walk the sidewalk at 4.00 am and not even look > behind you back , at the sanitation crew that clean the street to a > sparkling cleen . >',\n",
       " 'whoever of you have be there you know what I be say . >',\n",
       " 'I dont have any easy answer but if we as a nation do some selfcritisism > we might get somewhere . >',\n",
       " 'of course these posting sould be in soc.culture.us but if we reduce > crime here it will mean less car insurance rate , thus we could spend > more money on modife we car .',\n",
       " '-lrb- now my post be rec.autos.tech > revelant -rrb- . >',\n",
       " 'Vlasis Theodore > ___________________ > Software Engineer > IDB Mobile Communications . >',\n",
       " 'sig under development ... I remember this happen on the i-75 through Michigan and Ohio several year back .',\n",
       " 'a group of guy in a old beater would rear end a car , usually out of state or Canadians .',\n",
       " 'you stop and they smack you with a bb bat .',\n",
       " 'at least they do not kill you for the sake of a car .',\n",
       " 'I think the cop put out decoy and this calm down for a while .']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join([w[\"lemmma\"] for w in sent[\"tokens\"]]) for sent in newsparse[1200][\"sentences\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_tag(word_tokenize(newssent[idx_news][43])))\n",
    "print(pp.WNL.lemmatize(\"has\", wordnet.VERB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(newsparse[idx_news][\"sentences\"]))\n",
    "print(newsparse[idx_news][\"sentences\"][idx_sent].keys())\n",
    "examparse = newsparse[idx_news][\"sentences\"][idx_sent]\n",
    "print(examparse[\"enhancedPlusPlusDependencies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = Tree.fromstring(examparse[\"parse\"])\n",
    "tt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = [t[0] for t in top_terms[3]]\n",
    "t4_values = [t[1] for t in top_terms[3]]\n",
    "print(t4)\n",
    "print(t4_values)\n",
    "idxs, importance, count = relation.extract_important_sents(newssenttoken[idx_news], t4, t4_values)\n",
    "print(idxs, importance[40], count[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation.extract_word_relation_from_sent(i, newsparse[1200][\"sentences\"][sent_idx][\"enhancedDependencies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in top_terms[3]:\n",
    "    for news in top_docs[3]:\n",
    "        time.sleep(2)\n",
    "        news_idx = news[0]\n",
    "        for sent_idx,sent in enumerate(newssenttoken[news_idx]):\n",
    "            if type(newsparse[news_idx]) is str:\n",
    "                print(news_idx, \"parse\", \"err\")\n",
    "                break\n",
    "            topic_word_idxs = relation.get_word_idx(term[0], sent)\n",
    "            for i in topic_word_idxs:\n",
    "                print(sent_idx, i, news_idx)\n",
    "                rs = relation.extract_word_relation_from_sent(i, newsparse[news_idx][\"sentences\"][sent_idx][\"enhancedDependencies\"])\n",
    "                for r in rs:\n",
    "                    print(relation.convert_relation2str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tree.fromstring(newsparse[idx_news][\"sentences\"][5][\"parse\"])\n",
    "t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"exampleres.json\",encoding=\"utf8\")as f:\n",
    "    res = json.load(f)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda362",
   "language": "python",
   "name": "lda362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
