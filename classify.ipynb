{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not use stanford CoreNLP client!\n"
     ]
    }
   ],
   "source": [
    "import preprocess as pp\n",
    "import configs\n",
    "import persister\n",
    "import relation\n",
    "import lda\n",
    "import evaluate\n",
    "import embedding\n",
    "from utils import *\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 7\n",
    "t = 50\n",
    "m = \"c_v\"\n",
    "i = 200\n",
    "min_df = 1\n",
    "size = 100\n",
    "parse = persister.read_parse()\n",
    "_input = persister.read_input(configs.NEWSINPUT)\n",
    "model_name = configs.NEWSMODEL.format(l, t, m, i, min_df)\n",
    "terms, doc_topic, topic_word = persister.read_lda(configs.NEWSLDA.format(model_name))\n",
    "model = persister.load_model(model_name)\n",
    "vec = persister.load_model(configs.NEWSVEC.format(min_df))\n",
    "w2vmodel = persister.load_wv(configs.NEWSWV.format(size))\n",
    "tf = vec.fit_transform(_input)\n",
    "top_terms, top_docs = lda.get_topics(topic_word, terms, doc_topic, 10)\n",
    "word_values = []\n",
    "for i in top_terms:\n",
    "    tmp = []\n",
    "    for j in i:\n",
    "        tmp.append((terms[j[0]], j[1]))\n",
    "#         tmp.append(terms[j[0]])\n",
    "    word_values.append(tmp)\n",
    "df_top_words, df_top_docs = lda.pd_topics_vis(word_values, top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = relation.extend_lda_results(parse, _input, top_terms, top_docs, terms, \"originalText\", top_n=10, score_method=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8075\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, test_data, test_label = evaluate.split_data_set(doc_topic)\n",
    "print(evaluate.svm(train_data, train_label, test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2875\n"
     ]
    }
   ],
   "source": [
    "words, weights = evaluate.normalize_top_terms(top_terms, terms)\n",
    "hybrid_data = evaluate.get_hybrid_feature(_input, w2vmodel, words, weights)\n",
    "train_data, train_label, test_data, test_label = evaluate.split_data_set(hybrid_data)\n",
    "print(evaluate.svm(train_data, train_label, test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_words,_ = evaluate.filter_words(extended, topic_word, vec, top_terms, top_docs, _input, terms)\n",
    "words, weights = evaluate.convert_extended_words2weights(extended_words, topic_word, vec)\n",
    "hybrid_data = evaluate.get_hybrid_feature(_input, w2vmodel, words, weights)\n",
    "train_data, train_label, test_data, test_label = evaluate.split_data_set(hybrid_data)\n",
    "evaluate.svm(train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41043970e-02,  1.89622361e-02,  6.31992333e-03,  1.00738704e-02,\n",
       "       -1.55927306e-02, -2.17699143e-03,  1.77599827e-03,  5.73018054e-03,\n",
       "       -1.65819712e-02,  1.28262043e-02, -7.14619877e-03,  4.60338872e-03,\n",
       "        1.40667625e-03, -1.20086772e-02, -1.13446955e-02, -2.25290004e-03,\n",
       "        7.10217841e-03,  8.95414315e-03,  9.60995350e-03,  1.06498161e-02,\n",
       "       -1.52899083e-04, -1.35321133e-02,  8.45884133e-05,  2.29108240e-03,\n",
       "        3.33277276e-03,  4.99730790e-03,  3.25394957e-03,  5.74186258e-03,\n",
       "        1.59190316e-02,  6.05825335e-03, -7.22621195e-03, -7.98995513e-03,\n",
       "        1.20820878e-02, -2.56545283e-03, -1.21602369e-02,  3.90509202e-04,\n",
       "       -3.53875756e-03, -3.07417149e-03, -7.16265989e-03,  5.15754009e-03,\n",
       "       -2.44596098e-02, -4.66752099e-03,  6.43143337e-03, -1.40998475e-02,\n",
       "       -8.85499269e-03, -6.16792915e-03, -1.38281647e-03,  3.11542791e-03,\n",
       "        4.02312446e-03, -2.40615662e-03,  8.75603873e-03, -1.02104256e-02,\n",
       "       -5.55870123e-03, -7.25468679e-04,  3.18973511e-03,  4.46179789e-03,\n",
       "       -6.29888987e-03, -1.68048795e-02, -1.31549966e-02,  6.69842632e-03,\n",
       "       -1.33225629e-02, -3.19483271e-03, -3.29900323e-03,  2.06216099e-03,\n",
       "       -4.05941019e-03,  9.65835713e-03,  8.21713265e-03,  1.04897013e-02,\n",
       "        7.11640227e-04,  5.93835488e-03, -3.26825364e-04, -8.37693631e-04,\n",
       "       -2.94133672e-03,  1.65826501e-03, -6.67818356e-03, -1.37277292e-02,\n",
       "        2.96665495e-03,  4.74611670e-03,  2.09084843e-04,  5.62196248e-04,\n",
       "        4.62553609e-04,  1.04493517e-02,  8.10885394e-04, -1.23103382e-04,\n",
       "       -1.10453218e-02,  2.11387221e-03, -7.48478621e-03, -8.58890591e-04,\n",
       "        1.81313474e-02, -9.28295404e-03,  8.64455663e-03,  7.94963620e-04,\n",
       "       -1.17503619e-02,  2.09086668e-02,  7.71150179e-03, -4.64870688e-03,\n",
       "       -1.08141117e-02, -1.01204524e-02, -1.36712929e-02,  3.22279288e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv[\"assess\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, weights = evaluate.normalize_top_terms(top_terms, terms)\n",
    "for idx,w in enumerate(words):\n",
    "    s = evaluate.get_topic_vec(w,weights[idx],w2vmodel)\n",
    "    if not s.any():\n",
    "        print(w)\n",
    "        v = []\n",
    "        for ww in w:\n",
    "            if ww in w2vmodel.wv:\n",
    "                v.append(True)\n",
    "            else:\n",
    "                v.append(False)\n",
    "        print(v)\n",
    "        print([e[0] for e in weights[idx]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda362",
   "language": "python",
   "name": "lda362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
