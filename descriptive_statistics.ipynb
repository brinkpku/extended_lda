{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not use stanford CoreNLP client!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading sentiwordnet: <urlopen error [Errno 111]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    }
   ],
   "source": [
    "import preprocess as pp\n",
    "import configs\n",
    "import persister\n",
    "import relation\n",
    "import lda\n",
    "import vis\n",
    "from utils import *\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tree import Tree\n",
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load abs\n"
     ]
    }
   ],
   "source": [
    "# is_news = 1\n",
    "\n",
    "# l = 7\n",
    "# t = 4\n",
    "# m = \"c_v\"\n",
    "# i = 200\n",
    "# min_df = 1\n",
    "\n",
    "is_news = 0\n",
    "l = 6\n",
    "t = 14\n",
    "m = \"c_v\"\n",
    "i = 200\n",
    "min_df = 1\n",
    "\n",
    "# load\n",
    "if is_news:\n",
    "    _raw = persister.load_json(configs.RAWNEWS)\n",
    "    parse = persister.read_parse()\n",
    "    _input = persister.read_input(configs.NEWSINPUT)\n",
    "    model_name = configs.NEWSMODEL.format(l, t, m, i, min_df)\n",
    "    terms, doc_topic, topic_word = persister.read_lda(configs.NEWSLDA.format(model_name))\n",
    "    model = persister.load_model(model_name)\n",
    "    vec = persister.load_model(configs.NEWSVEC.format(min_df))\n",
    "    print(\"load news\")\n",
    "else:\n",
    "    _raw = persister.load_json(configs.RAWABSTRACT)\n",
    "    _input = persister.read_input(configs.ABSTRACTINPUT)\n",
    "    model_name = configs.ABSTRACTMODEL.format(l, t, m, i, min_df)\n",
    "    terms, doc_topic, topic_word = persister.read_lda(configs.ABSTRACTLDA.format(model_name))\n",
    "    parse = persister.read_parse(configs.ABSTRACTPARSE)\n",
    "    model = persister.load_model(model_name)\n",
    "    vec = persister.load_model(configs.ABSVEC.format(min_df))\n",
    "    print(\"load abs\")\n",
    "tf = vec.fit_transform(_input) \n",
    "top_terms, top_docs = lda.get_topics(topic_word, terms, doc_topic)\n",
    "df_top_words, df_top_docs = lda.pd_topics_vis(top_terms, top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs distribution: {9: 152, 5: 33, 11: 969, 12: 1330, 1: 7, 13: 3, 10: 76, 3: 3, 0: 8, 7: 14, 6: 1}\n"
     ]
    }
   ],
   "source": [
    "distr = lda.get_dominant_topic(doc_topic)\n",
    "print(\"docs distribution:\",dict(Counter(distr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top terms info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "      <th>Word 15</th>\n",
       "      <th>Word 16</th>\n",
       "      <th>Word 17</th>\n",
       "      <th>Word 18</th>\n",
       "      <th>Word 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>(gene, 123.1)</td>\n",
       "      <td>(drug, 96.87)</td>\n",
       "      <td>(expression, 78.19)</td>\n",
       "      <td>(disease, 77.49)</td>\n",
       "      <td>(protein, 75.45)</td>\n",
       "      <td>(biomedical, 64.39)</td>\n",
       "      <td>(pathway, 51.34)</td>\n",
       "      <td>(cell, 51.19)</td>\n",
       "      <td>(identify, 48.51)</td>\n",
       "      <td>(biological, 47.03)</td>\n",
       "      <td>(btm, 40.99)</td>\n",
       "      <td>(ad, 40.76)</td>\n",
       "      <td>(study, 39.19)</td>\n",
       "      <td>(apply, 37.74)</td>\n",
       "      <td>(manufacturing, 31.56)</td>\n",
       "      <td>(mrna, 29.42)</td>\n",
       "      <td>(relationship, 29.31)</td>\n",
       "      <td>(conclusion, 28.59)</td>\n",
       "      <td>(tool, 26.52)</td>\n",
       "      <td>(related, 25.93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>(patient, 223.06)</td>\n",
       "      <td>(medical, 143.69)</td>\n",
       "      <td>(health, 143.5)</td>\n",
       "      <td>(clinical, 139.72)</td>\n",
       "      <td>(treatment, 99.44)</td>\n",
       "      <td>(diagnosis, 86.78)</td>\n",
       "      <td>(disease, 81.07)</td>\n",
       "      <td>(risk, 79.0)</td>\n",
       "      <td>(record, 78.67)</td>\n",
       "      <td>(care, 68.06)</td>\n",
       "      <td>(friend, 47.64)</td>\n",
       "      <td>(healthcare, 42.31)</td>\n",
       "      <td>(cancer, 39.36)</td>\n",
       "      <td>(code, 36.28)</td>\n",
       "      <td>(data, 32.74)</td>\n",
       "      <td>(conclusion, 30.77)</td>\n",
       "      <td>(physician, 29.99)</td>\n",
       "      <td>(emr, 25.48)</td>\n",
       "      <td>(ehr, 25.13)</td>\n",
       "      <td>(doctor, 24.57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>(mirna, 42.64)</td>\n",
       "      <td>(permission, 25.17)</td>\n",
       "      <td>(quran, 13.82)</td>\n",
       "      <td>(holy, 9.76)</td>\n",
       "      <td>(aircraft, 8.0)</td>\n",
       "      <td>(provenance, 7.74)</td>\n",
       "      <td>(lv, 7.74)</td>\n",
       "      <td>(laplace, 7.05)</td>\n",
       "      <td>(ast, 6.96)</td>\n",
       "      <td>(chara, 6.65)</td>\n",
       "      <td>(yuru, 6.65)</td>\n",
       "      <td>(ldaclm, 6.22)</td>\n",
       "      <td>(privilege, 5.86)</td>\n",
       "      <td>(mmrm, 5.86)</td>\n",
       "      <td>(iexpand, 5.13)</td>\n",
       "      <td>(configure, 5.01)</td>\n",
       "      <td>(transcriptional, 5.0)</td>\n",
       "      <td>(pcfg, 4.14)</td>\n",
       "      <td>(tctm, 4.12)</td>\n",
       "      <td>(seqlda, 4.12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>(emotion, 181.73)</td>\n",
       "      <td>(drive, 87.04)</td>\n",
       "      <td>(style, 86.19)</td>\n",
       "      <td>(speech, 55.34)</td>\n",
       "      <td>(genre, 39.85)</td>\n",
       "      <td>(recognition, 38.09)</td>\n",
       "      <td>(speaker, 34.84)</td>\n",
       "      <td>(state, 33.33)</td>\n",
       "      <td>(write, 31.62)</td>\n",
       "      <td>(language, 30.16)</td>\n",
       "      <td>(acoustic, 30.1)</td>\n",
       "      <td>(driving, 29.08)</td>\n",
       "      <td>(driver, 27.25)</td>\n",
       "      <td>(essay, 26.57)</td>\n",
       "      <td>(sleep, 24.96)</td>\n",
       "      <td>(vehicle, 24.49)</td>\n",
       "      <td>(authorship, 22.67)</td>\n",
       "      <td>(noca, 22.09)</td>\n",
       "      <td>(author, 21.59)</td>\n",
       "      <td>(disorder, 21.36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>(sampling, 79.5)</td>\n",
       "      <td>(parallel, 73.15)</td>\n",
       "      <td>(gibbs, 67.68)</td>\n",
       "      <td>(security, 57.19)</td>\n",
       "      <td>(distribute, 52.59)</td>\n",
       "      <td>(collapse, 42.46)</td>\n",
       "      <td>(cluster, 33.26)</td>\n",
       "      <td>(bot, 32.4)</td>\n",
       "      <td>(brand, 31.0)</td>\n",
       "      <td>(large, 30.54)</td>\n",
       "      <td>(crime, 29.71)</td>\n",
       "      <td>(scale, 29.68)</td>\n",
       "      <td>(token, 29.34)</td>\n",
       "      <td>(approximation, 28.55)</td>\n",
       "      <td>(memory, 27.44)</td>\n",
       "      <td>(gpu, 27.32)</td>\n",
       "      <td>(sampler, 26.77)</td>\n",
       "      <td>(matrix, 23.32)</td>\n",
       "      <td>(atomic, 23.12)</td>\n",
       "      <td>(mh, 22.88)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>(review, 537.88)</td>\n",
       "      <td>(sentiment, 474.31)</td>\n",
       "      <td>(opinion, 265.32)</td>\n",
       "      <td>(tweet, 235.55)</td>\n",
       "      <td>(product, 228.45)</td>\n",
       "      <td>(post, 206.48)</td>\n",
       "      <td>(online, 196.94)</td>\n",
       "      <td>(topic, 194.3)</td>\n",
       "      <td>(analysis, 180.66)</td>\n",
       "      <td>(twitter, 174.52)</td>\n",
       "      <td>(media, 171.56)</td>\n",
       "      <td>(aspect, 166.01)</td>\n",
       "      <td>(customer, 159.65)</td>\n",
       "      <td>(rating, 142.65)</td>\n",
       "      <td>(consumer, 111.75)</td>\n",
       "      <td>(social, 101.7)</td>\n",
       "      <td>(use, 101.33)</td>\n",
       "      <td>(negative, 88.63)</td>\n",
       "      <td>(positive, 85.19)</td>\n",
       "      <td>(study, 81.34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>(song, 81.12)</td>\n",
       "      <td>(audio, 74.02)</td>\n",
       "      <td>(music, 57.13)</td>\n",
       "      <td>(pn, 35.01)</td>\n",
       "      <td>(broadcast, 28.77)</td>\n",
       "      <td>(oov, 24.22)</td>\n",
       "      <td>(indonesian, 19.81)</td>\n",
       "      <td>(musical, 18.49)</td>\n",
       "      <td>(lyric, 17.49)</td>\n",
       "      <td>(estimate, 16.39)</td>\n",
       "      <td>(writer, 14.97)</td>\n",
       "      <td>(commonness, 14.53)</td>\n",
       "      <td>(submit, 13.59)</td>\n",
       "      <td>(hyperspectral, 11.69)</td>\n",
       "      <td>(eem, 10.71)</td>\n",
       "      <td>(mp, 10.39)</td>\n",
       "      <td>(isoform, 9.79)</td>\n",
       "      <td>(retrieve, 9.73)</td>\n",
       "      <td>(replicate, 9.62)</td>\n",
       "      <td>(timbre, 8.87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>(software, 268.18)</td>\n",
       "      <td>(question, 203.92)</td>\n",
       "      <td>(code, 149.7)</td>\n",
       "      <td>(developer, 143.61)</td>\n",
       "      <td>(source, 143.52)</td>\n",
       "      <td>(bug, 139.43)</td>\n",
       "      <td>(report, 120.26)</td>\n",
       "      <td>(project, 87.55)</td>\n",
       "      <td>(program, 68.98)</td>\n",
       "      <td>(answer, 65.81)</td>\n",
       "      <td>(repository, 53.22)</td>\n",
       "      <td>(requirement, 49.86)</td>\n",
       "      <td>(evolution, 49.8)</td>\n",
       "      <td>(technique, 48.97)</td>\n",
       "      <td>(open, 44.34)</td>\n",
       "      <td>(study, 43.24)</td>\n",
       "      <td>(lsi, 40.78)</td>\n",
       "      <td>(stack, 33.35)</td>\n",
       "      <td>(change, 30.56)</td>\n",
       "      <td>(nfr, 30.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>(lm, 75.09)</td>\n",
       "      <td>(frame, 55.04)</td>\n",
       "      <td>(library, 31.56)</td>\n",
       "      <td>(asr, 28.23)</td>\n",
       "      <td>(street, 22.76)</td>\n",
       "      <td>(ldta, 18.42)</td>\n",
       "      <td>(adr, 18.41)</td>\n",
       "      <td>(rnn, 17.93)</td>\n",
       "      <td>(abbreviation, 15.75)</td>\n",
       "      <td>(adverse, 15.54)</td>\n",
       "      <td>(adapted, 15.29)</td>\n",
       "      <td>(lsm, 13.09)</td>\n",
       "      <td>(eligibility, 13.06)</td>\n",
       "      <td>(india, 12.3)</td>\n",
       "      <td>(attraction, 11.6)</td>\n",
       "      <td>(salience, 11.02)</td>\n",
       "      <td>(wall, 10.98)</td>\n",
       "      <td>(grams, 10.91)</td>\n",
       "      <td>(journal, 10.27)</td>\n",
       "      <td>(dntm, 10.12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>(topic, 893.39)</td>\n",
       "      <td>(research, 662.45)</td>\n",
       "      <td>(study, 393.56)</td>\n",
       "      <td>(analysis, 331.47)</td>\n",
       "      <td>(use, 254.09)</td>\n",
       "      <td>(article, 239.38)</td>\n",
       "      <td>(identify, 225.84)</td>\n",
       "      <td>(technology, 215.99)</td>\n",
       "      <td>(trend, 201.75)</td>\n",
       "      <td>(literature, 154.3)</td>\n",
       "      <td>(field, 150.61)</td>\n",
       "      <td>(text, 137.1)</td>\n",
       "      <td>(papers, 135.72)</td>\n",
       "      <td>(latent, 131.54)</td>\n",
       "      <td>(patent, 131.04)</td>\n",
       "      <td>(researcher, 130.56)</td>\n",
       "      <td>(scientific, 129.8)</td>\n",
       "      <td>(area, 125.64)</td>\n",
       "      <td>(dirichlet, 123.53)</td>\n",
       "      <td>(allocation, 122.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 10</th>\n",
       "      <td>(image, 923.95)</td>\n",
       "      <td>(feature, 404.79)</td>\n",
       "      <td>(object, 384.84)</td>\n",
       "      <td>(video, 298.9)</td>\n",
       "      <td>(visual, 296.7)</td>\n",
       "      <td>(scene, 291.52)</td>\n",
       "      <td>(propose, 268.69)</td>\n",
       "      <td>(method, 208.2)</td>\n",
       "      <td>(level, 190.16)</td>\n",
       "      <td>(model, 189.69)</td>\n",
       "      <td>(spatial, 171.52)</td>\n",
       "      <td>(region, 157.06)</td>\n",
       "      <td>(annotation, 151.42)</td>\n",
       "      <td>(classification, 148.49)</td>\n",
       "      <td>(human, 143.97)</td>\n",
       "      <td>(recognition, 138.61)</td>\n",
       "      <td>(result, 128.93)</td>\n",
       "      <td>(framework, 127.79)</td>\n",
       "      <td>(segmentation, 122.98)</td>\n",
       "      <td>(motion, 117.66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 11</th>\n",
       "      <td>(user, 1748.72)</td>\n",
       "      <td>(use, 1591.63)</td>\n",
       "      <td>(datum, 1381.07)</td>\n",
       "      <td>(topic, 1103.26)</td>\n",
       "      <td>(information, 1036.7)</td>\n",
       "      <td>(method, 971.08)</td>\n",
       "      <td>(latent, 941.61)</td>\n",
       "      <td>(propose, 858.59)</td>\n",
       "      <td>(allocation, 801.15)</td>\n",
       "      <td>(social, 798.08)</td>\n",
       "      <td>(approach, 753.49)</td>\n",
       "      <td>(dirichlet, 750.28)</td>\n",
       "      <td>(model, 704.64)</td>\n",
       "      <td>(result, 701.73)</td>\n",
       "      <td>(base, 692.76)</td>\n",
       "      <td>(network, 607.05)</td>\n",
       "      <td>(lda, 589.42)</td>\n",
       "      <td>(service, 569.67)</td>\n",
       "      <td>(paper, 561.59)</td>\n",
       "      <td>(time, 553.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 12</th>\n",
       "      <td>(topic, 5025.38)</td>\n",
       "      <td>(model, 4893.76)</td>\n",
       "      <td>(lda, 2687.1)</td>\n",
       "      <td>(latent, 2152.96)</td>\n",
       "      <td>(document, 1992.37)</td>\n",
       "      <td>(use, 1943.68)</td>\n",
       "      <td>(method, 1839.26)</td>\n",
       "      <td>(word, 1773.7)</td>\n",
       "      <td>(dirichlet, 1564.05)</td>\n",
       "      <td>(propose, 1468.27)</td>\n",
       "      <td>(text, 1357.69)</td>\n",
       "      <td>(allocation, 1355.55)</td>\n",
       "      <td>(result, 1055.09)</td>\n",
       "      <td>(base, 997.56)</td>\n",
       "      <td>(approach, 918.45)</td>\n",
       "      <td>(paper, 905.81)</td>\n",
       "      <td>(algorithm, 897.52)</td>\n",
       "      <td>(datum, 891.62)</td>\n",
       "      <td>(feature, 814.18)</td>\n",
       "      <td>(information, 704.53)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 13</th>\n",
       "      <td>(hashtag, 94.97)</td>\n",
       "      <td>(membership, 54.98)</td>\n",
       "      <td>(chain, 51.44)</td>\n",
       "      <td>(routine, 49.23)</td>\n",
       "      <td>(functional, 38.29)</td>\n",
       "      <td>(carlo, 35.55)</td>\n",
       "      <td>(monte, 35.55)</td>\n",
       "      <td>(population, 30.26)</td>\n",
       "      <td>(incident, 26.4)</td>\n",
       "      <td>(trait, 24.96)</td>\n",
       "      <td>(signature, 23.26)</td>\n",
       "      <td>(poi, 23.24)</td>\n",
       "      <td>(ecosystem, 22.99)</td>\n",
       "      <td>(personality, 22.4)</td>\n",
       "      <td>(tissue, 21.34)</td>\n",
       "      <td>(hyperparameter, 21.08)</td>\n",
       "      <td>(composition, 20.08)</td>\n",
       "      <td>(zone, 19.08)</td>\n",
       "      <td>(site, 18.45)</td>\n",
       "      <td>(type, 17.93)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Word 0               Word 1               Word 2  \\\n",
       "Topic 0        (gene, 123.1)        (drug, 96.87)  (expression, 78.19)   \n",
       "Topic 1    (patient, 223.06)    (medical, 143.69)      (health, 143.5)   \n",
       "Topic 2       (mirna, 42.64)  (permission, 25.17)       (quran, 13.82)   \n",
       "Topic 3    (emotion, 181.73)       (drive, 87.04)       (style, 86.19)   \n",
       "Topic 4     (sampling, 79.5)    (parallel, 73.15)       (gibbs, 67.68)   \n",
       "Topic 5     (review, 537.88)  (sentiment, 474.31)    (opinion, 265.32)   \n",
       "Topic 6        (song, 81.12)       (audio, 74.02)       (music, 57.13)   \n",
       "Topic 7   (software, 268.18)   (question, 203.92)        (code, 149.7)   \n",
       "Topic 8          (lm, 75.09)       (frame, 55.04)     (library, 31.56)   \n",
       "Topic 9      (topic, 893.39)   (research, 662.45)      (study, 393.56)   \n",
       "Topic 10     (image, 923.95)    (feature, 404.79)     (object, 384.84)   \n",
       "Topic 11     (user, 1748.72)       (use, 1591.63)     (datum, 1381.07)   \n",
       "Topic 12    (topic, 5025.38)     (model, 4893.76)        (lda, 2687.1)   \n",
       "Topic 13    (hashtag, 94.97)  (membership, 54.98)       (chain, 51.44)   \n",
       "\n",
       "                       Word 3                 Word 4                Word 5  \\\n",
       "Topic 0      (disease, 77.49)       (protein, 75.45)   (biomedical, 64.39)   \n",
       "Topic 1    (clinical, 139.72)     (treatment, 99.44)    (diagnosis, 86.78)   \n",
       "Topic 2          (holy, 9.76)        (aircraft, 8.0)    (provenance, 7.74)   \n",
       "Topic 3       (speech, 55.34)         (genre, 39.85)  (recognition, 38.09)   \n",
       "Topic 4     (security, 57.19)    (distribute, 52.59)     (collapse, 42.46)   \n",
       "Topic 5       (tweet, 235.55)      (product, 228.45)        (post, 206.48)   \n",
       "Topic 6           (pn, 35.01)     (broadcast, 28.77)          (oov, 24.22)   \n",
       "Topic 7   (developer, 143.61)       (source, 143.52)         (bug, 139.43)   \n",
       "Topic 8          (asr, 28.23)        (street, 22.76)         (ldta, 18.42)   \n",
       "Topic 9    (analysis, 331.47)          (use, 254.09)     (article, 239.38)   \n",
       "Topic 10       (video, 298.9)        (visual, 296.7)       (scene, 291.52)   \n",
       "Topic 11     (topic, 1103.26)  (information, 1036.7)      (method, 971.08)   \n",
       "Topic 12    (latent, 2152.96)    (document, 1992.37)        (use, 1943.68)   \n",
       "Topic 13     (routine, 49.23)    (functional, 38.29)        (carlo, 35.55)   \n",
       "\n",
       "                       Word 6                Word 7                 Word 8  \\\n",
       "Topic 0      (pathway, 51.34)         (cell, 51.19)      (identify, 48.51)   \n",
       "Topic 1      (disease, 81.07)          (risk, 79.0)        (record, 78.67)   \n",
       "Topic 2            (lv, 7.74)       (laplace, 7.05)            (ast, 6.96)   \n",
       "Topic 3      (speaker, 34.84)        (state, 33.33)         (write, 31.62)   \n",
       "Topic 4      (cluster, 33.26)           (bot, 32.4)          (brand, 31.0)   \n",
       "Topic 5      (online, 196.94)        (topic, 194.3)     (analysis, 180.66)   \n",
       "Topic 6   (indonesian, 19.81)      (musical, 18.49)         (lyric, 17.49)   \n",
       "Topic 7      (report, 120.26)      (project, 87.55)       (program, 68.98)   \n",
       "Topic 8          (adr, 18.41)          (rnn, 17.93)  (abbreviation, 15.75)   \n",
       "Topic 9    (identify, 225.84)  (technology, 215.99)        (trend, 201.75)   \n",
       "Topic 10    (propose, 268.69)       (method, 208.2)        (level, 190.16)   \n",
       "Topic 11     (latent, 941.61)     (propose, 858.59)   (allocation, 801.15)   \n",
       "Topic 12    (method, 1839.26)        (word, 1773.7)   (dirichlet, 1564.05)   \n",
       "Topic 13       (monte, 35.55)   (population, 30.26)       (incident, 26.4)   \n",
       "\n",
       "                       Word 9              Word 10                Word 11  \\\n",
       "Topic 0   (biological, 47.03)         (btm, 40.99)            (ad, 40.76)   \n",
       "Topic 1         (care, 68.06)      (friend, 47.64)    (healthcare, 42.31)   \n",
       "Topic 2         (chara, 6.65)         (yuru, 6.65)         (ldaclm, 6.22)   \n",
       "Topic 3     (language, 30.16)     (acoustic, 30.1)       (driving, 29.08)   \n",
       "Topic 4        (large, 30.54)       (crime, 29.71)         (scale, 29.68)   \n",
       "Topic 5     (twitter, 174.52)      (media, 171.56)       (aspect, 166.01)   \n",
       "Topic 6     (estimate, 16.39)      (writer, 14.97)    (commonness, 14.53)   \n",
       "Topic 7       (answer, 65.81)  (repository, 53.22)   (requirement, 49.86)   \n",
       "Topic 8      (adverse, 15.54)     (adapted, 15.29)           (lsm, 13.09)   \n",
       "Topic 9   (literature, 154.3)      (field, 150.61)          (text, 137.1)   \n",
       "Topic 10      (model, 189.69)    (spatial, 171.52)       (region, 157.06)   \n",
       "Topic 11     (social, 798.08)   (approach, 753.49)    (dirichlet, 750.28)   \n",
       "Topic 12   (propose, 1468.27)      (text, 1357.69)  (allocation, 1355.55)   \n",
       "Topic 13       (trait, 24.96)   (signature, 23.26)           (poi, 23.24)   \n",
       "\n",
       "                       Word 12                   Word 13  \\\n",
       "Topic 0         (study, 39.19)            (apply, 37.74)   \n",
       "Topic 1        (cancer, 39.36)             (code, 36.28)   \n",
       "Topic 2      (privilege, 5.86)              (mmrm, 5.86)   \n",
       "Topic 3        (driver, 27.25)            (essay, 26.57)   \n",
       "Topic 4         (token, 29.34)    (approximation, 28.55)   \n",
       "Topic 5     (customer, 159.65)          (rating, 142.65)   \n",
       "Topic 6        (submit, 13.59)    (hyperspectral, 11.69)   \n",
       "Topic 7      (evolution, 49.8)        (technique, 48.97)   \n",
       "Topic 8   (eligibility, 13.06)             (india, 12.3)   \n",
       "Topic 9       (papers, 135.72)          (latent, 131.54)   \n",
       "Topic 10  (annotation, 151.42)  (classification, 148.49)   \n",
       "Topic 11       (model, 704.64)          (result, 701.73)   \n",
       "Topic 12     (result, 1055.09)            (base, 997.56)   \n",
       "Topic 13    (ecosystem, 22.99)       (personality, 22.4)   \n",
       "\n",
       "                         Word 14                  Word 15  \\\n",
       "Topic 0   (manufacturing, 31.56)            (mrna, 29.42)   \n",
       "Topic 1            (data, 32.74)      (conclusion, 30.77)   \n",
       "Topic 2          (iexpand, 5.13)        (configure, 5.01)   \n",
       "Topic 3           (sleep, 24.96)         (vehicle, 24.49)   \n",
       "Topic 4          (memory, 27.44)             (gpu, 27.32)   \n",
       "Topic 5       (consumer, 111.75)          (social, 101.7)   \n",
       "Topic 6             (eem, 10.71)              (mp, 10.39)   \n",
       "Topic 7            (open, 44.34)           (study, 43.24)   \n",
       "Topic 8       (attraction, 11.6)        (salience, 11.02)   \n",
       "Topic 9         (patent, 131.04)     (researcher, 130.56)   \n",
       "Topic 10         (human, 143.97)    (recognition, 138.61)   \n",
       "Topic 11          (base, 692.76)        (network, 607.05)   \n",
       "Topic 12      (approach, 918.45)          (paper, 905.81)   \n",
       "Topic 13         (tissue, 21.34)  (hyperparameter, 21.08)   \n",
       "\n",
       "                         Word 16              Word 17                 Word 18  \\\n",
       "Topic 0    (relationship, 29.31)  (conclusion, 28.59)           (tool, 26.52)   \n",
       "Topic 1       (physician, 29.99)         (emr, 25.48)            (ehr, 25.13)   \n",
       "Topic 2   (transcriptional, 5.0)         (pcfg, 4.14)            (tctm, 4.12)   \n",
       "Topic 3      (authorship, 22.67)        (noca, 22.09)         (author, 21.59)   \n",
       "Topic 4         (sampler, 26.77)      (matrix, 23.32)         (atomic, 23.12)   \n",
       "Topic 5            (use, 101.33)    (negative, 88.63)       (positive, 85.19)   \n",
       "Topic 6          (isoform, 9.79)     (retrieve, 9.73)       (replicate, 9.62)   \n",
       "Topic 7             (lsi, 40.78)       (stack, 33.35)         (change, 30.56)   \n",
       "Topic 8            (wall, 10.98)       (grams, 10.91)        (journal, 10.27)   \n",
       "Topic 9      (scientific, 129.8)       (area, 125.64)     (dirichlet, 123.53)   \n",
       "Topic 10        (result, 128.93)  (framework, 127.79)  (segmentation, 122.98)   \n",
       "Topic 11           (lda, 589.42)    (service, 569.67)         (paper, 561.59)   \n",
       "Topic 12     (algorithm, 897.52)      (datum, 891.62)       (feature, 814.18)   \n",
       "Topic 13    (composition, 20.08)        (zone, 19.08)           (site, 18.45)   \n",
       "\n",
       "                        Word 19  \n",
       "Topic 0        (related, 25.93)  \n",
       "Topic 1         (doctor, 24.57)  \n",
       "Topic 2          (seqlda, 4.12)  \n",
       "Topic 3       (disorder, 21.36)  \n",
       "Topic 4             (mh, 22.88)  \n",
       "Topic 5          (study, 81.34)  \n",
       "Topic 6          (timbre, 8.87)  \n",
       "Topic 7            (nfr, 30.05)  \n",
       "Topic 8           (dntm, 10.12)  \n",
       "Topic 9    (allocation, 122.98)  \n",
       "Topic 10       (motion, 117.66)  \n",
       "Topic 11         (time, 553.23)  \n",
       "Topic 12  (information, 704.53)  \n",
       "Topic 13          (type, 17.93)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"top terms info:\")\n",
    "df_top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top docs info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>(198, 0.548)</td>\n",
       "      <td>(263, 0.493)</td>\n",
       "      <td>(107, 0.407)</td>\n",
       "      <td>(1764, 0.386)</td>\n",
       "      <td>(2009, 0.383)</td>\n",
       "      <td>(1770, 0.371)</td>\n",
       "      <td>(1740, 0.361)</td>\n",
       "      <td>(894, 0.346)</td>\n",
       "      <td>(896, 0.334)</td>\n",
       "      <td>(65, 0.32)</td>\n",
       "      <td>(751, 0.318)</td>\n",
       "      <td>(725, 0.318)</td>\n",
       "      <td>(122, 0.314)</td>\n",
       "      <td>(52, 0.285)</td>\n",
       "      <td>(2577, 0.271)</td>\n",
       "      <td>(562, 0.264)</td>\n",
       "      <td>(526, 0.263)</td>\n",
       "      <td>(50, 0.257)</td>\n",
       "      <td>(685, 0.247)</td>\n",
       "      <td>(2248, 0.245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>(489, 0.751)</td>\n",
       "      <td>(142, 0.651)</td>\n",
       "      <td>(115, 0.587)</td>\n",
       "      <td>(722, 0.42)</td>\n",
       "      <td>(1566, 0.37)</td>\n",
       "      <td>(1101, 0.364)</td>\n",
       "      <td>(1112, 0.346)</td>\n",
       "      <td>(80, 0.346)</td>\n",
       "      <td>(32, 0.345)</td>\n",
       "      <td>(627, 0.339)</td>\n",
       "      <td>(415, 0.319)</td>\n",
       "      <td>(2304, 0.319)</td>\n",
       "      <td>(1037, 0.313)</td>\n",
       "      <td>(1446, 0.291)</td>\n",
       "      <td>(1402, 0.291)</td>\n",
       "      <td>(1129, 0.281)</td>\n",
       "      <td>(174, 0.277)</td>\n",
       "      <td>(64, 0.276)</td>\n",
       "      <td>(338, 0.275)</td>\n",
       "      <td>(1624, 0.266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>(1855, 0.23)</td>\n",
       "      <td>(1319, 0.208)</td>\n",
       "      <td>(1400, 0.199)</td>\n",
       "      <td>(872, 0.198)</td>\n",
       "      <td>(1309, 0.196)</td>\n",
       "      <td>(1079, 0.187)</td>\n",
       "      <td>(1340, 0.151)</td>\n",
       "      <td>(1310, 0.146)</td>\n",
       "      <td>(1164, 0.133)</td>\n",
       "      <td>(1350, 0.131)</td>\n",
       "      <td>(2158, 0.115)</td>\n",
       "      <td>(2386, 0.114)</td>\n",
       "      <td>(2188, 0.112)</td>\n",
       "      <td>(1242, 0.11)</td>\n",
       "      <td>(2220, 0.107)</td>\n",
       "      <td>(1868, 0.105)</td>\n",
       "      <td>(1932, 0.104)</td>\n",
       "      <td>(2422, 0.102)</td>\n",
       "      <td>(2457, 0.075)</td>\n",
       "      <td>(1876, 0.074)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>(81, 0.685)</td>\n",
       "      <td>(874, 0.517)</td>\n",
       "      <td>(109, 0.374)</td>\n",
       "      <td>(771, 0.349)</td>\n",
       "      <td>(18, 0.338)</td>\n",
       "      <td>(195, 0.293)</td>\n",
       "      <td>(1178, 0.287)</td>\n",
       "      <td>(344, 0.285)</td>\n",
       "      <td>(1281, 0.265)</td>\n",
       "      <td>(1813, 0.255)</td>\n",
       "      <td>(171, 0.254)</td>\n",
       "      <td>(1422, 0.254)</td>\n",
       "      <td>(1761, 0.244)</td>\n",
       "      <td>(1306, 0.24)</td>\n",
       "      <td>(1266, 0.238)</td>\n",
       "      <td>(737, 0.233)</td>\n",
       "      <td>(1278, 0.228)</td>\n",
       "      <td>(113, 0.222)</td>\n",
       "      <td>(1175, 0.22)</td>\n",
       "      <td>(365, 0.216)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>(508, 0.371)</td>\n",
       "      <td>(461, 0.346)</td>\n",
       "      <td>(413, 0.333)</td>\n",
       "      <td>(98, 0.282)</td>\n",
       "      <td>(1076, 0.27)</td>\n",
       "      <td>(720, 0.268)</td>\n",
       "      <td>(740, 0.268)</td>\n",
       "      <td>(741, 0.268)</td>\n",
       "      <td>(1666, 0.252)</td>\n",
       "      <td>(606, 0.248)</td>\n",
       "      <td>(693, 0.247)</td>\n",
       "      <td>(2027, 0.247)</td>\n",
       "      <td>(1379, 0.246)</td>\n",
       "      <td>(82, 0.241)</td>\n",
       "      <td>(2447, 0.231)</td>\n",
       "      <td>(886, 0.226)</td>\n",
       "      <td>(89, 0.225)</td>\n",
       "      <td>(1273, 0.217)</td>\n",
       "      <td>(450, 0.215)</td>\n",
       "      <td>(56, 0.206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>(85, 0.951)</td>\n",
       "      <td>(57, 0.727)</td>\n",
       "      <td>(386, 0.669)</td>\n",
       "      <td>(111, 0.651)</td>\n",
       "      <td>(1, 0.631)</td>\n",
       "      <td>(575, 0.57)</td>\n",
       "      <td>(434, 0.518)</td>\n",
       "      <td>(698, 0.513)</td>\n",
       "      <td>(1577, 0.493)</td>\n",
       "      <td>(786, 0.486)</td>\n",
       "      <td>(103, 0.48)</td>\n",
       "      <td>(59, 0.471)</td>\n",
       "      <td>(6, 0.466)</td>\n",
       "      <td>(270, 0.455)</td>\n",
       "      <td>(957, 0.454)</td>\n",
       "      <td>(2272, 0.452)</td>\n",
       "      <td>(67, 0.452)</td>\n",
       "      <td>(973, 0.451)</td>\n",
       "      <td>(410, 0.435)</td>\n",
       "      <td>(1936, 0.42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>(1570, 0.465)</td>\n",
       "      <td>(1117, 0.415)</td>\n",
       "      <td>(1606, 0.337)</td>\n",
       "      <td>(477, 0.302)</td>\n",
       "      <td>(757, 0.276)</td>\n",
       "      <td>(970, 0.254)</td>\n",
       "      <td>(1874, 0.252)</td>\n",
       "      <td>(1167, 0.169)</td>\n",
       "      <td>(1520, 0.166)</td>\n",
       "      <td>(684, 0.162)</td>\n",
       "      <td>(1668, 0.15)</td>\n",
       "      <td>(854, 0.147)</td>\n",
       "      <td>(2526, 0.144)</td>\n",
       "      <td>(702, 0.141)</td>\n",
       "      <td>(581, 0.141)</td>\n",
       "      <td>(1021, 0.131)</td>\n",
       "      <td>(2325, 0.126)</td>\n",
       "      <td>(2396, 0.125)</td>\n",
       "      <td>(1720, 0.124)</td>\n",
       "      <td>(995, 0.12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>(1586, 0.575)</td>\n",
       "      <td>(747, 0.526)</td>\n",
       "      <td>(224, 0.503)</td>\n",
       "      <td>(831, 0.447)</td>\n",
       "      <td>(453, 0.428)</td>\n",
       "      <td>(898, 0.427)</td>\n",
       "      <td>(20, 0.397)</td>\n",
       "      <td>(1594, 0.396)</td>\n",
       "      <td>(731, 0.392)</td>\n",
       "      <td>(2283, 0.386)</td>\n",
       "      <td>(380, 0.385)</td>\n",
       "      <td>(1473, 0.382)</td>\n",
       "      <td>(891, 0.379)</td>\n",
       "      <td>(1181, 0.377)</td>\n",
       "      <td>(2312, 0.376)</td>\n",
       "      <td>(2533, 0.375)</td>\n",
       "      <td>(945, 0.371)</td>\n",
       "      <td>(2467, 0.368)</td>\n",
       "      <td>(752, 0.357)</td>\n",
       "      <td>(141, 0.357)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>(441, 0.215)</td>\n",
       "      <td>(1958, 0.173)</td>\n",
       "      <td>(890, 0.172)</td>\n",
       "      <td>(626, 0.172)</td>\n",
       "      <td>(2121, 0.167)</td>\n",
       "      <td>(2184, 0.165)</td>\n",
       "      <td>(70, 0.161)</td>\n",
       "      <td>(802, 0.16)</td>\n",
       "      <td>(1442, 0.157)</td>\n",
       "      <td>(273, 0.152)</td>\n",
       "      <td>(2561, 0.148)</td>\n",
       "      <td>(1343, 0.147)</td>\n",
       "      <td>(1440, 0.137)</td>\n",
       "      <td>(576, 0.136)</td>\n",
       "      <td>(2505, 0.129)</td>\n",
       "      <td>(2233, 0.125)</td>\n",
       "      <td>(1882, 0.123)</td>\n",
       "      <td>(849, 0.114)</td>\n",
       "      <td>(2522, 0.113)</td>\n",
       "      <td>(621, 0.108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>(2, 0.994)</td>\n",
       "      <td>(41, 0.9)</td>\n",
       "      <td>(1044, 0.871)</td>\n",
       "      <td>(317, 0.861)</td>\n",
       "      <td>(1013, 0.836)</td>\n",
       "      <td>(97, 0.813)</td>\n",
       "      <td>(996, 0.8)</td>\n",
       "      <td>(47, 0.798)</td>\n",
       "      <td>(1475, 0.772)</td>\n",
       "      <td>(335, 0.772)</td>\n",
       "      <td>(1305, 0.772)</td>\n",
       "      <td>(388, 0.765)</td>\n",
       "      <td>(308, 0.755)</td>\n",
       "      <td>(120, 0.752)</td>\n",
       "      <td>(546, 0.741)</td>\n",
       "      <td>(51, 0.737)</td>\n",
       "      <td>(8, 0.727)</td>\n",
       "      <td>(617, 0.724)</td>\n",
       "      <td>(264, 0.716)</td>\n",
       "      <td>(564, 0.712)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 10</th>\n",
       "      <td>(745, 0.69)</td>\n",
       "      <td>(399, 0.664)</td>\n",
       "      <td>(291, 0.662)</td>\n",
       "      <td>(2580, 0.654)</td>\n",
       "      <td>(2520, 0.652)</td>\n",
       "      <td>(1111, 0.645)</td>\n",
       "      <td>(1224, 0.645)</td>\n",
       "      <td>(284, 0.642)</td>\n",
       "      <td>(760, 0.638)</td>\n",
       "      <td>(695, 0.633)</td>\n",
       "      <td>(1694, 0.626)</td>\n",
       "      <td>(1410, 0.624)</td>\n",
       "      <td>(1222, 0.621)</td>\n",
       "      <td>(1900, 0.618)</td>\n",
       "      <td>(374, 0.612)</td>\n",
       "      <td>(2339, 0.605)</td>\n",
       "      <td>(662, 0.604)</td>\n",
       "      <td>(2363, 0.598)</td>\n",
       "      <td>(1550, 0.589)</td>\n",
       "      <td>(538, 0.582)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 11</th>\n",
       "      <td>(14, 0.994)</td>\n",
       "      <td>(149, 0.993)</td>\n",
       "      <td>(529, 0.993)</td>\n",
       "      <td>(619, 0.992)</td>\n",
       "      <td>(392, 0.991)</td>\n",
       "      <td>(2018, 0.989)</td>\n",
       "      <td>(1526, 0.989)</td>\n",
       "      <td>(1997, 0.988)</td>\n",
       "      <td>(162, 0.988)</td>\n",
       "      <td>(1549, 0.987)</td>\n",
       "      <td>(1180, 0.987)</td>\n",
       "      <td>(2326, 0.987)</td>\n",
       "      <td>(974, 0.987)</td>\n",
       "      <td>(2503, 0.986)</td>\n",
       "      <td>(206, 0.985)</td>\n",
       "      <td>(589, 0.985)</td>\n",
       "      <td>(485, 0.983)</td>\n",
       "      <td>(1741, 0.982)</td>\n",
       "      <td>(1862, 0.982)</td>\n",
       "      <td>(1703, 0.98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 12</th>\n",
       "      <td>(966, 0.992)</td>\n",
       "      <td>(739, 0.991)</td>\n",
       "      <td>(1033, 0.991)</td>\n",
       "      <td>(1075, 0.991)</td>\n",
       "      <td>(2306, 0.991)</td>\n",
       "      <td>(354, 0.991)</td>\n",
       "      <td>(211, 0.991)</td>\n",
       "      <td>(870, 0.991)</td>\n",
       "      <td>(1071, 0.991)</td>\n",
       "      <td>(2168, 0.991)</td>\n",
       "      <td>(1408, 0.99)</td>\n",
       "      <td>(173, 0.99)</td>\n",
       "      <td>(1788, 0.99)</td>\n",
       "      <td>(1704, 0.99)</td>\n",
       "      <td>(1828, 0.99)</td>\n",
       "      <td>(2543, 0.99)</td>\n",
       "      <td>(422, 0.99)</td>\n",
       "      <td>(824, 0.99)</td>\n",
       "      <td>(390, 0.989)</td>\n",
       "      <td>(2477, 0.989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 13</th>\n",
       "      <td>(53, 0.618)</td>\n",
       "      <td>(377, 0.343)</td>\n",
       "      <td>(158, 0.312)</td>\n",
       "      <td>(1762, 0.288)</td>\n",
       "      <td>(55, 0.285)</td>\n",
       "      <td>(356, 0.284)</td>\n",
       "      <td>(1744, 0.278)</td>\n",
       "      <td>(1499, 0.255)</td>\n",
       "      <td>(288, 0.225)</td>\n",
       "      <td>(342, 0.222)</td>\n",
       "      <td>(665, 0.221)</td>\n",
       "      <td>(75, 0.206)</td>\n",
       "      <td>(1045, 0.199)</td>\n",
       "      <td>(68, 0.194)</td>\n",
       "      <td>(1003, 0.189)</td>\n",
       "      <td>(777, 0.189)</td>\n",
       "      <td>(269, 0.186)</td>\n",
       "      <td>(1657, 0.164)</td>\n",
       "      <td>(601, 0.164)</td>\n",
       "      <td>(562, 0.162)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0              1              2              3  \\\n",
       "Topic 0    (198, 0.548)   (263, 0.493)   (107, 0.407)  (1764, 0.386)   \n",
       "Topic 1    (489, 0.751)   (142, 0.651)   (115, 0.587)    (722, 0.42)   \n",
       "Topic 2    (1855, 0.23)  (1319, 0.208)  (1400, 0.199)   (872, 0.198)   \n",
       "Topic 3     (81, 0.685)   (874, 0.517)   (109, 0.374)   (771, 0.349)   \n",
       "Topic 4    (508, 0.371)   (461, 0.346)   (413, 0.333)    (98, 0.282)   \n",
       "Topic 5     (85, 0.951)    (57, 0.727)   (386, 0.669)   (111, 0.651)   \n",
       "Topic 6   (1570, 0.465)  (1117, 0.415)  (1606, 0.337)   (477, 0.302)   \n",
       "Topic 7   (1586, 0.575)   (747, 0.526)   (224, 0.503)   (831, 0.447)   \n",
       "Topic 8    (441, 0.215)  (1958, 0.173)   (890, 0.172)   (626, 0.172)   \n",
       "Topic 9      (2, 0.994)      (41, 0.9)  (1044, 0.871)   (317, 0.861)   \n",
       "Topic 10    (745, 0.69)   (399, 0.664)   (291, 0.662)  (2580, 0.654)   \n",
       "Topic 11    (14, 0.994)   (149, 0.993)   (529, 0.993)   (619, 0.992)   \n",
       "Topic 12   (966, 0.992)   (739, 0.991)  (1033, 0.991)  (1075, 0.991)   \n",
       "Topic 13    (53, 0.618)   (377, 0.343)   (158, 0.312)  (1762, 0.288)   \n",
       "\n",
       "                      4              5              6              7  \\\n",
       "Topic 0   (2009, 0.383)  (1770, 0.371)  (1740, 0.361)   (894, 0.346)   \n",
       "Topic 1    (1566, 0.37)  (1101, 0.364)  (1112, 0.346)    (80, 0.346)   \n",
       "Topic 2   (1309, 0.196)  (1079, 0.187)  (1340, 0.151)  (1310, 0.146)   \n",
       "Topic 3     (18, 0.338)   (195, 0.293)  (1178, 0.287)   (344, 0.285)   \n",
       "Topic 4    (1076, 0.27)   (720, 0.268)   (740, 0.268)   (741, 0.268)   \n",
       "Topic 5      (1, 0.631)    (575, 0.57)   (434, 0.518)   (698, 0.513)   \n",
       "Topic 6    (757, 0.276)   (970, 0.254)  (1874, 0.252)  (1167, 0.169)   \n",
       "Topic 7    (453, 0.428)   (898, 0.427)    (20, 0.397)  (1594, 0.396)   \n",
       "Topic 8   (2121, 0.167)  (2184, 0.165)    (70, 0.161)    (802, 0.16)   \n",
       "Topic 9   (1013, 0.836)    (97, 0.813)     (996, 0.8)    (47, 0.798)   \n",
       "Topic 10  (2520, 0.652)  (1111, 0.645)  (1224, 0.645)   (284, 0.642)   \n",
       "Topic 11   (392, 0.991)  (2018, 0.989)  (1526, 0.989)  (1997, 0.988)   \n",
       "Topic 12  (2306, 0.991)   (354, 0.991)   (211, 0.991)   (870, 0.991)   \n",
       "Topic 13    (55, 0.285)   (356, 0.284)  (1744, 0.278)  (1499, 0.255)   \n",
       "\n",
       "                      8              9             10             11  \\\n",
       "Topic 0    (896, 0.334)     (65, 0.32)   (751, 0.318)   (725, 0.318)   \n",
       "Topic 1     (32, 0.345)   (627, 0.339)   (415, 0.319)  (2304, 0.319)   \n",
       "Topic 2   (1164, 0.133)  (1350, 0.131)  (2158, 0.115)  (2386, 0.114)   \n",
       "Topic 3   (1281, 0.265)  (1813, 0.255)   (171, 0.254)  (1422, 0.254)   \n",
       "Topic 4   (1666, 0.252)   (606, 0.248)   (693, 0.247)  (2027, 0.247)   \n",
       "Topic 5   (1577, 0.493)   (786, 0.486)    (103, 0.48)    (59, 0.471)   \n",
       "Topic 6   (1520, 0.166)   (684, 0.162)   (1668, 0.15)   (854, 0.147)   \n",
       "Topic 7    (731, 0.392)  (2283, 0.386)   (380, 0.385)  (1473, 0.382)   \n",
       "Topic 8   (1442, 0.157)   (273, 0.152)  (2561, 0.148)  (1343, 0.147)   \n",
       "Topic 9   (1475, 0.772)   (335, 0.772)  (1305, 0.772)   (388, 0.765)   \n",
       "Topic 10   (760, 0.638)   (695, 0.633)  (1694, 0.626)  (1410, 0.624)   \n",
       "Topic 11   (162, 0.988)  (1549, 0.987)  (1180, 0.987)  (2326, 0.987)   \n",
       "Topic 12  (1071, 0.991)  (2168, 0.991)   (1408, 0.99)    (173, 0.99)   \n",
       "Topic 13   (288, 0.225)   (342, 0.222)   (665, 0.221)    (75, 0.206)   \n",
       "\n",
       "                     12             13             14             15  \\\n",
       "Topic 0    (122, 0.314)    (52, 0.285)  (2577, 0.271)   (562, 0.264)   \n",
       "Topic 1   (1037, 0.313)  (1446, 0.291)  (1402, 0.291)  (1129, 0.281)   \n",
       "Topic 2   (2188, 0.112)   (1242, 0.11)  (2220, 0.107)  (1868, 0.105)   \n",
       "Topic 3   (1761, 0.244)   (1306, 0.24)  (1266, 0.238)   (737, 0.233)   \n",
       "Topic 4   (1379, 0.246)    (82, 0.241)  (2447, 0.231)   (886, 0.226)   \n",
       "Topic 5      (6, 0.466)   (270, 0.455)   (957, 0.454)  (2272, 0.452)   \n",
       "Topic 6   (2526, 0.144)   (702, 0.141)   (581, 0.141)  (1021, 0.131)   \n",
       "Topic 7    (891, 0.379)  (1181, 0.377)  (2312, 0.376)  (2533, 0.375)   \n",
       "Topic 8   (1440, 0.137)   (576, 0.136)  (2505, 0.129)  (2233, 0.125)   \n",
       "Topic 9    (308, 0.755)   (120, 0.752)   (546, 0.741)    (51, 0.737)   \n",
       "Topic 10  (1222, 0.621)  (1900, 0.618)   (374, 0.612)  (2339, 0.605)   \n",
       "Topic 11   (974, 0.987)  (2503, 0.986)   (206, 0.985)   (589, 0.985)   \n",
       "Topic 12   (1788, 0.99)   (1704, 0.99)   (1828, 0.99)   (2543, 0.99)   \n",
       "Topic 13  (1045, 0.199)    (68, 0.194)  (1003, 0.189)   (777, 0.189)   \n",
       "\n",
       "                     16             17             18             19  \n",
       "Topic 0    (526, 0.263)    (50, 0.257)   (685, 0.247)  (2248, 0.245)  \n",
       "Topic 1    (174, 0.277)    (64, 0.276)   (338, 0.275)  (1624, 0.266)  \n",
       "Topic 2   (1932, 0.104)  (2422, 0.102)  (2457, 0.075)  (1876, 0.074)  \n",
       "Topic 3   (1278, 0.228)   (113, 0.222)   (1175, 0.22)   (365, 0.216)  \n",
       "Topic 4     (89, 0.225)  (1273, 0.217)   (450, 0.215)    (56, 0.206)  \n",
       "Topic 5     (67, 0.452)   (973, 0.451)   (410, 0.435)   (1936, 0.42)  \n",
       "Topic 6   (2325, 0.126)  (2396, 0.125)  (1720, 0.124)    (995, 0.12)  \n",
       "Topic 7    (945, 0.371)  (2467, 0.368)   (752, 0.357)   (141, 0.357)  \n",
       "Topic 8   (1882, 0.123)   (849, 0.114)  (2522, 0.113)   (621, 0.108)  \n",
       "Topic 9      (8, 0.727)   (617, 0.724)   (264, 0.716)   (564, 0.712)  \n",
       "Topic 10   (662, 0.604)  (2363, 0.598)  (1550, 0.589)   (538, 0.582)  \n",
       "Topic 11   (485, 0.983)  (1741, 0.982)  (1862, 0.982)   (1703, 0.98)  \n",
       "Topic 12    (422, 0.99)    (824, 0.99)   (390, 0.989)  (2477, 0.989)  \n",
       "Topic 13   (269, 0.186)  (1657, 0.164)   (601, 0.164)   (562, 0.162)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"top docs info:\")\n",
    "df_top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.pyLDA(topic_word, doc_topic, [len(s) for s in [word_tokenize(corp) for corp in _input]], vec.get_feature_names(), np.array(sum(tf).todense())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'parse', 'basicDependencies', 'enhancedDependencies', 'enhancedPlusPlusDependencies', 'tokens'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse[0][\"sentences\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### ('patient', 223.06) ####################\n",
      "3 12 489\n",
      "latent Dirichlet allocation ( lda ) may offer statistical rigor in summarize patient ' concern and cope strategy in a life-threatening illness .\n",
      "concerns - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "4 20 489\n",
      "we aim to apply LDA to interview datum collect as part of a prospective , longitudinal study of qol in patient undergo radical cystectomy and urinary diversion for bladder cancer .\n",
      "patients - [case] - in\n",
      "QOL - [nmod:in] - patients\n",
      "patients - [acl] - undergoing\n",
      "5 8 489\n",
      "lda show that , prior to surgery , patient ' priority be primarily in cancer surgery and recovery .\n",
      "priorities - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "2 16 115\n",
      "latent Dirichlet allocation ( lda ) offer statistical rigor and consistency in automate the interpretation of patient ' express concern and cope strategy .\n",
      "patients - [case] - of\n",
      "interpretation - [nmod:'] - patients\n",
      "patients - [case] - '\n",
      "patients - [dep] - concerns\n",
      "3 22 115\n",
      "method LDA be apply to interview datum collect as part of a prospective , longitudinal study of qol in n = 211 patient undergo radical cystectomy and urinary diversion for bladder cancer .\n",
      "patients - [nummod] - 211\n",
      "= - [dep] - patients\n",
      "patients - [acl] - undergoing\n",
      "4 20 115\n",
      "lda analyze personal goal statement to extract the latent topic and theme , stratify by time , and on thing patient want to accomplish and prevent .\n",
      "patients - [case] - on\n",
      "patients - [compound] - things\n",
      "analyzed - [dobj] - patients\n",
      "statements - [conj:and] - patients\n",
      "patients - [acl] - wanted\n",
      "7 4 115\n",
      "prior to surgery , patient ' priority be primarily in cancer surgery and recovery .\n",
      "priorities - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "0 24 722\n",
      "the present study aim to investigate difference in prognosis base on human papillomavirus ( hpv ) infection , persistent infection and genotype variation for patient exhibit atypical squamous cell of undetermined significance ( ascus ) in they initial Papanicolaou ( PAP ) test result .\n",
      "patients - [case] - for\n",
      "infection - [nmod:for] - patients\n",
      "patients - [acl] - exhibiting\n",
      "2 5 722\n",
      "the present study assess 491 patient ( 139 hpv-positive and 352 hpv-negative case ) with a PAP test result of ascus with a follow-up period > = 2 year .\n",
      "patients - [nummod] - 491\n",
      "assessed - [dobj] - patients\n",
      "patients - [dep] - HPV-positive\n",
      "patients - [dep] - cases\n",
      "patients - [nmod:with] - result\n",
      "3 0 722\n",
      "patient undergo PAP and HPV DNA chip test between January 2006 and January 2009 .\n",
      "underwent - [nsubj] - Patients\n",
      "6 8 722\n",
      "a total of 33.3 % ( 12/36 ) patient positive for hpv-16 have cervical intraepithelial neoplasia ( cin ) 2 or a worse result , which be significantly higher than the prevalence of cin2 of 1.8 % ( 8/455 ) in patient negative for hpv-16 ( p < 0.001 ) , while no significant association be identify for other genotype in term of genotype and clinical progress .\n",
      "% - [dep] - patients\n",
      "patients - [amod] - positive\n",
      "6 41 722\n",
      "a total of 33.3 % ( 12/36 ) patient positive for hpv-16 have cervical intraepithelial neoplasia ( cin ) 2 or a worse result , which be significantly higher than the prevalence of cin2 of 1.8 % ( 8/455 ) in patient negative for hpv-16 ( p < 0.001 ) , while no significant association be identify for other genotype in term of genotype and clinical progress .\n",
      "patients - [case] - in\n",
      "prevalence - [nmod:in] - patients\n",
      "patients - [amod] - negative\n",
      "8 5 722\n",
      "persistent infection be higher in patient aged > = 51 year ( 38.7 % ) than in those aged < = 50 year ( 20.4 % ; p = 0.036 ) .\n",
      "patients - [case] - in\n",
      "higher - [nmod:in] - patients\n",
      "patients - [amod] - aged\n",
      "12 21 722\n",
      "therefore , lda result may be present as explanatory evidence during time-constrained patient-doctor consultation in order to deliver information regard the patient 's status .\n",
      "patient - [det] - the\n",
      "status - [nmod:poss] - patient\n",
      "patient - [case] - 's\n",
      "1 24 1566\n",
      "by examine the clinical observation ( such as diagnosis , risk factor , and medication ) mention in longitudinal emr , we can use patient ' medical chronology to automatically predict the progression of they pathology .\n",
      "chronologies - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "2 19 1566\n",
      "in this paper , we present a novel probabilistic model which jointly learn how to ( 1 ) group patient base on the similarity between they clinical observation as well as how to ( 2 ) predict the way a new patient 's clinical observation might evolve in the future .\n",
      "patients - [compound] - group\n",
      "1 - [dobj] - patients\n",
      "patients - [acl] - based\n",
      "2 41 1566\n",
      "in this paper , we present a novel probabilistic model which jointly learn how to ( 1 ) group patient base on the similarity between they clinical observation as well as how to ( 2 ) predict the way a new patient 's clinical observation might evolve in the future .\n",
      "patient - [det] - a\n",
      "patient - [amod] - new\n",
      "observations - [nmod:poss] - patient\n",
      "patient - [case] - 's\n",
      "3 14 1566\n",
      "we show that we model can be use to not only track how a patient 's clinical finding might change over time , but to also identify which patient be due for preventative visit .\n",
      "patient - [det] - a\n",
      "findings - [nmod:poss] - patient\n",
      "patient - [case] - 's\n",
      "3 28 1566\n",
      "we show that we model can be use to not only track how a patient 's clinical finding might change over time , but to also identify which patient be due for preventative visit .\n",
      "due - [nsubj] - patients\n",
      "4 14 1566\n",
      "in addition , we model have the potential to improve the quality of over-all patient care in practice by predict the most likely set of clinical observation at a arbitrary point in the future .\n",
      "care - [compound] - patient\n",
      "1 11 1101\n",
      "a hospital emr dataset typically consist of medical record of hospitalize patient .\n",
      "patients - [case] - of\n",
      "patients - [amod] - hospitalized\n",
      "records - [nmod:of] - patients\n",
      "3 32 1101\n",
      "traditional topic model , such as latent dirichlet allocation ( lda ) and hierarchical dirichlet process ( hdp ) , can be employ to discover disease topic from emr datum by treat patient as document and diagnosis code as word .\n",
      "treating - [dobj] - patients\n",
      "4 9 1101\n",
      "this topic modeling help to understand the constitution of patient disease and offer a tool for better planning of treatment .\n",
      "diseases - [compound] - patient\n",
      "0 27 1112\n",
      "information and communication technology have enable healthcare institution to accumulate large amount of healthcare datum that include diagnosis , medication , and additional contextual information such as patient demographic .\n",
      "demographics - [compound] - patient\n",
      "9 36 80\n",
      "however , this study suggest that imperfect datum ( e.g. , icd code in combination with other ehr feature ) can serve as a silver standard to develop a risk model , apply that model to patient without dementia code , and then select a case-detection threshold .\n",
      "patients - [case] - to\n",
      "apply - [nmod:to] - patients\n",
      "patients - [nmod:without] - codes\n",
      "1 17 32\n",
      "predict diabetic complication be regard as a highly effective technique for increase the survival rate of diabetic patient .\n",
      "patients - [case] - of\n",
      "patients - [amod] - diabetic\n",
      "rate - [nmod:of] - patients\n",
      "2 10 415\n",
      "mkl method be use to divide parameter between heart disease patient and normal individual .\n",
      "patients - [case] - between\n",
      "patients - [compound] - heart\n",
      "patients - [compound] - disease\n",
      "parameters - [nmod:between] - patients\n",
      "patients - [cc] - and\n",
      "patients - [conj:and] - individuals\n",
      "3 20 415\n",
      "the result obtain from the mkl method be give to the ANFIS classifier to classify the heart disease and healthy patient .\n",
      "patients - [amod] - healthy\n",
      "classify - [dobj] - patients\n",
      "disease - [conj:and] - patients\n",
      "5 10 2304\n",
      "the result show that manifestation sub-category actually exist in t2dm patient that need specific , individualised cm therapy .\n",
      "patients - [case] - in\n",
      "patients - [compound] - T2DM\n",
      "exist - [nmod:in] - patients\n",
      "need - [nsubj] - patients\n",
      "patients - [ref] - that\n",
      "patients - [acl:relcl] - need\n",
      "5 2 1037\n",
      "of 4687 patient with inpatient discharge summary , 470 be readmit within 30 day .\n",
      "patients - [case] - Of\n",
      "patients - [nummod] - 4687\n",
      "readmitted - [nmod:of] - patients\n",
      "patients - [nmod:with] - summaries\n",
      "0 26 1446\n",
      "clinical pathway ( cp ) analysis play a important role in health-care management in ensure specialize , standardized , normalize and sophisticated therapy procedure for individual patient .\n",
      "patients - [case] - for\n",
      "patients - [amod] - individual\n",
      "procedures - [nmod:for] - patients\n",
      "3 11 1446\n",
      "more specifically , we develop a probabilistic topic model to link patient feature and treatment behavior together to mine treatment pattern hide in emr .\n",
      "features - [compound] - patient\n",
      "4 13 1446\n",
      "discover treatment pattern , as actionable knowledge represent the best practice for most patient in most time of they treatment process , form the backbone of cp , and can be exploit to help physician better understand they specialty and learn from previous experience for cp analysis and improvement .\n",
      "patients - [case] - for\n",
      "patients - [amod] - most\n",
      "practice - [nmod:for] - patients\n",
      "0 16 1402\n",
      "background and objective : risk stratification aim to provide physician with the accurate assessment of a patient 's clinical risk such that a individualized prevention or management strategy can be develop and deliver .\n",
      "patient - [det] - a\n",
      "risk - [nmod:poss] - patient\n",
      "patient - [case] - 's\n",
      "1 14 1402\n",
      "exist risk stratification technique mainly focus on predict the overall risk of a individual patient in a supervised manner , and , at the cohort level , often offer little insight beyond a flat score-based segmentation from the label clinical dataset .\n",
      "patient - [case] - of\n",
      "patient - [det] - an\n",
      "patient - [amod] - individual\n",
      "risk - [nmod:of] - patient\n",
      "patient - [nmod:in] - manner\n",
      "4 5 1402\n",
      "the propose PRSM recognize a patient clinical state as a probabilistic combination of latent sub-profile , and generate sub-profile-specific risk tier of patient from they ehr in a fully unsupervised fashion .\n",
      "state - [compound] - patient\n",
      "4 22 1402\n",
      "the propose PRSM recognize a patient clinical state as a probabilistic combination of latent sub-profile , and generate sub-profile-specific risk tier of patient from they ehr in a fully unsupervised fashion .\n",
      "patients - [case] - of\n",
      "tiers - [nmod:of] - patients\n",
      "patients - [nmod:from] - EHRs\n",
      "7 22 1402\n",
      "result : we verify the effectiveness of the propose approach on a clinical dataset contain 3463 coronary heart disease ( chd ) patient instance .\n",
      "instances - [compound] - patient\n",
      "12 2 1402\n",
      "moreover , patient sub-profile and sub-profile-specific risk tier generate by we model be coherent and informative , and provide significant potential to be explore for the further task , such as patient cohort analysis .\n",
      "sub-profiles - [compound] - patient\n",
      "12 31 1402\n",
      "moreover , patient sub-profile and sub-profile-specific risk tier generate by we model be coherent and informative , and provide significant potential to be explore for the further task , such as patient cohort analysis .\n",
      "analysis - [compound] - patient\n",
      "0 17 1129\n",
      "in healthcare organizational setting , the design of a clinical pathway ( cp ) be challenge since patient follow a particular pathway may have not only one single first-diagnosis but also several typical comorbidity , and thus it require different discipline involve to put together they partial knowledge about the overall pathway .\n",
      "patients - [case] - since\n",
      "challenging - [nmod:since] - patients\n",
      "patients - [nmod:following] - pathway\n",
      "7 15 1129\n",
      "we verify the effectiveness of the propose model on a real clinical dataset contain 12,120 patient trace , which pertain to the unstable angina cp .\n",
      "traces - [compound] - patient\n",
      "0 10 174\n",
      "objective few study have examine ankylose spondylitis ( as ) patient ' concern about and perception of biologic therapy , apart from traditional survey .\n",
      "concerns - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "1 20 174\n",
      "in this study , we use social media data to examine the knowledge , attitude , and belief of as patient regard biologic therapy .\n",
      "patients - [case] - of\n",
      "patients - [amod] - AS\n",
      "beliefs - [nmod:of] - patients\n",
      "patients - [acl] - regarding\n",
      "11 2 174\n",
      "additional implicit patient need ( e.g. , support ) be identify use qualitative analysis .\n",
      "needs - [compound] - patient\n",
      "12 11 174\n",
      "conclusion Social media reveal a dynamic range of theme govern as patient ' experience with and choice of biologic agent .\n",
      "patients - [amod] - AS\n",
      "experience - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "13 25 174\n",
      "the complexity of select biologic from among many such agent and navigate they risk/benefit profile suggest the merit of create online tool tailor to support patient ' decision-making with regard to biologic therapy for as .\n",
      "decision-making - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "4 25 338\n",
      "objective : this study aim to develop a hierarchical topic taxonomy to uncover the latent structure of physician review and illustrate its application for mining patient ' interest base on the propose taxonomy and algorithm .\n",
      "patients - [compound] - mining\n",
      "interests - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "9 8 338\n",
      "the patient-related domain include the category of the patient profile , symptom , diagnosis , and pathogenesis .\n",
      "profile - [compound] - patient\n",
      "12 26 338\n",
      "symptom ( Cohen d = 1.58 , Delta u = 0.216 , t = 229.75 , and p < .001 ) be more often mention by patient with acute disease , whereas communication skill ( Cohen d = -0.29 , Delta u = -0.038 , t = -42.01 , and p < .001 ) , financing ( Cohen d = -0.68 , Delta u = -0.098 , t = -99.26 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -0.55 , Delta u = -0.078 , t = -80.09 , and p < .001 ) be more often mention by patient with chronic disease .\n",
      "patients - [case] - by\n",
      "mentioned - [nmod:agent] - patients\n",
      "patients - [nmod:with] - diseases\n",
      "12 106 338\n",
      "symptom ( Cohen d = 1.58 , Delta u = 0.216 , t = 229.75 , and p < .001 ) be more often mention by patient with acute disease , whereas communication skill ( Cohen d = -0.29 , Delta u = -0.038 , t = -42.01 , and p < .001 ) , financing ( Cohen d = -0.68 , Delta u = -0.098 , t = -99.26 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -0.55 , Delta u = -0.078 , t = -80.09 , and p < .001 ) be more often mention by patient with chronic disease .\n",
      "patients - [case] - by\n",
      "mentioned - [nmod:agent] - patients\n",
      "patients - [nmod:with] - diseases\n",
      "13 0 338\n",
      "patient with mild disease be more interested in medical ethic ( Cohen d = 0.25 , Delta u 0.039 , t = 8.33 , and p < .001 ) , operation process ( Cohen d = 0.57 , Delta u 0.060 , t = 18.75 , and p < .001 ) , patient profile ( Cohen d = 1.19 , Delta u 0.132 , t = 39.33 , and p < .001 ) , and symptom ( Cohen d = 1.91 , Delta u = 0.274 , t = 62.82 , and p < .001 ) .\n",
      "interested - [nsubj] - Patients\n",
      "Patients - [nmod:with] - diseases\n",
      "13 52 338\n",
      "patient with mild disease be more interested in medical ethic ( Cohen d = 0.25 , Delta u 0.039 , t = 8.33 , and p < .001 ) , operation process ( Cohen d = 0.57 , Delta u 0.060 , t = 18.75 , and p < .001 ) , patient profile ( Cohen d = 1.19 , Delta u 0.132 , t = 39.33 , and p < .001 ) , and symptom ( Cohen d = 1.91 , Delta u = 0.274 , t = 62.82 , and p < .001 ) .\n",
      "profile - [compound] - patient\n",
      "14 2 338\n",
      "meanwhile , patient with serious disease be more interested in medical competence ( Cohen d = -0.99 , Delta u = -0.165 , t = -32.58 , and p < .001 ) , medical advice and prescription ( Cohen d = -0.65 , Delta u = -0.082 , t = -21.45 , and p < .001 ) , financing ( Cohen d = -0.26 , Delta u = -0.018 , t = -8.45 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -1.55 , Delta u = -0.229 , t = -50.93 , and p < .001 ) .\n",
      "interested - [nsubj] - patients\n",
      "patients - [nmod:with] - diseases\n",
      "16 15 338\n",
      "the propose algorithm base on labeled-latent Dirichlet allocation can achieve impressive classification result for mining patient ' interest .\n",
      "patients - [compound] - mining\n",
      "interests - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "17 9 338\n",
      "furthermore , the mining result reveal marked difference in patient ' interest across different disease type , socioeconomic development level , and hospital level .\n",
      "interests - [nmod:poss] - patients\n",
      "patients - [case] - '\n",
      "1 1 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "records - [compound] - patient\n",
      "1 8 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "information - [compound] - patient\n",
      "1 18 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "outcomes - [compound] - patient\n",
      "3 16 1624\n",
      "in this paper , we present a method for automatically discover underlie theme and pattern within patient datum .\n",
      "data - [compound] - patient\n",
      "#################### ('medical', 143.69) ####################\n",
      "0 10 1566\n",
      "the expand clinical information provide by the advent of electronic medical record offer a exciting opportunity to substantially improve the quality of health care .\n",
      "records - [amod] - medical\n",
      "1 26 1566\n",
      "by examine the clinical observation ( such as diagnosis , risk factor , and medication ) mention in longitudinal emr , we can use patient ' medical chronology to automatically predict the progression of they pathology .\n",
      "chronologies - [amod] - medical\n",
      "1 7 1101\n",
      "a hospital emr dataset typically consist of medical record of hospitalize patient .\n",
      "records - [amod] - medical\n",
      "2 1 1101\n",
      "a medical record contain diagnostic information ( diagnosis code ) , procedure perform ( procedure code ) and admission detail .\n",
      "record - [amod] - medical\n",
      "11 8 1101\n",
      "we evaluate the propose model on two real-world medical dataset - polyvascular disease and acute myocardial infarction disease .\n",
      "datasets - [amod] - medical\n",
      "2 5 32\n",
      "while many study currently use medical image and structured medical record , very limited effort have be dedicate to apply datum mining technique for unstructured textual medical record , such as admission and discharge record .\n",
      "images - [amod] - medical\n",
      "2 9 32\n",
      "while many study currently use medical image and structured medical record , very limited effort have be dedicate to apply datum mining technique for unstructured textual medical record , such as admission and discharge record .\n",
      "records - [amod] - medical\n",
      "2 26 32\n",
      "while many study currently use medical image and structured medical record , very limited effort have be dedicate to apply datum mining technique for unstructured textual medical record , such as admission and discharge record .\n",
      "records - [amod] - medical\n",
      "3 5 32\n",
      "moreover , the similarity among medical record that be overlook by exist approach could potentially improve the accuracy of prediction model .\n",
      "records - [amod] - medical\n",
      "5 9 32\n",
      "specifically , we first estimate the similarity between textual medical record after datum preprocessing , and then we perform selda-based diabetic complication topic mining base on similarity constraint .\n",
      "records - [amod] - medical\n",
      "0 2 627\n",
      "obstetric electronic medical record ( emr ) contain massive amount of medical datum and health information .\n",
      "records - [amod] - medical\n",
      "0 11 627\n",
      "obstetric electronic medical record ( emr ) contain massive amount of medical datum and health information .\n",
      "data - [amod] - medical\n",
      "6 15 627\n",
      "the result of the diagnosis assistant can be introduce as a supplementary learning method for medical student .\n",
      "students - [amod] - medical\n",
      "7 16 627\n",
      "additionally , the method can be use not only for obstetric emr but also for other medical record .\n",
      "records - [amod] - medical\n",
      "4 19 2304\n",
      "we obtain meaningful diagnosis and treatment topic ( cluster ) from the datum , which clinically indicate some important medical group correspond to comorbidity disease ( e.g. , heart disease and diabetic kidney disease in t2dm inpatient ) .\n",
      "groups - [amod] - medical\n",
      "1 16 1446\n",
      "recently , with the rapid development of hospital information system , a large volume of electronic medical record ( emr ) have be produce , which provide a comprehensive source for cp analysis .\n",
      "records - [amod] - medical\n",
      "9 5 1129\n",
      "in addition , a possible medical application in term of treatment recommendation be provide to illustrate the potential of the propose model .\n",
      "application - [amod] - medical\n",
      "9 12 174\n",
      "other theme , include the psychological impact of as , reporting of medical literature , and as disease consequence , account for the remain 40 % ( n = 45 ) .\n",
      "literature - [amod] - medical\n",
      "8 7 338\n",
      "the physician-related domain include the category of medical ethic , medical competence , communication skill , medical advice , and prescription .\n",
      "ethics - [amod] - medical\n",
      "8 10 338\n",
      "the physician-related domain include the category of medical ethic , medical competence , communication skill , medical advice , and prescription .\n",
      "competence - [amod] - medical\n",
      "8 16 338\n",
      "the physician-related domain include the category of medical ethic , medical competence , communication skill , medical advice , and prescription .\n",
      "advice - [amod] - medical\n",
      "13 8 338\n",
      "patient with mild disease be more interested in medical ethic ( Cohen d = 0.25 , Delta u 0.039 , t = 8.33 , and p < .001 ) , operation process ( Cohen d = 0.57 , Delta u 0.060 , t = 18.75 , and p < .001 ) , patient profile ( Cohen d = 1.19 , Delta u 0.132 , t = 39.33 , and p < .001 ) , and symptom ( Cohen d = 1.91 , Delta u = 0.274 , t = 62.82 , and p < .001 ) .\n",
      "ethics - [amod] - medical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 10 338\n",
      "meanwhile , patient with serious disease be more interested in medical competence ( Cohen d = -0.99 , Delta u = -0.165 , t = -32.58 , and p < .001 ) , medical advice and prescription ( Cohen d = -0.65 , Delta u = -0.082 , t = -21.45 , and p < .001 ) , financing ( Cohen d = -0.26 , Delta u = -0.018 , t = -8.45 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -1.55 , Delta u = -0.229 , t = -50.93 , and p < .001 ) .\n",
      "competence - [amod] - medical\n",
      "14 33 338\n",
      "meanwhile , patient with serious disease be more interested in medical competence ( Cohen d = -0.99 , Delta u = -0.165 , t = -32.58 , and p < .001 ) , medical advice and prescription ( Cohen d = -0.65 , Delta u = -0.082 , t = -21.45 , and p < .001 ) , financing ( Cohen d = -0.26 , Delta u = -0.018 , t = -8.45 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -1.55 , Delta u = -0.229 , t = -50.93 , and p < .001 ) .\n",
      "advice - [amod] - medical\n",
      "1 5 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "information - [amod] - medical\n",
      "#################### ('health', 143.5) ####################\n",
      "0 8 489\n",
      "as we begin to leverage Big Data in health care setting and particularly in assess patient-reported outcome , there be a need for novel analytic to address unique challenge .\n",
      "settings - [compound] - health\n",
      "0 9 115\n",
      "purpose as we begin to leverage Big Data in health care setting and particularly in assess patient-reported outcome , there be a need for novel analytic to address unique challenge .\n",
      "settings - [compound] - health\n",
      "0 22 1566\n",
      "the expand clinical information provide by the advent of electronic medical record offer a exciting opportunity to substantially improve the quality of health care .\n",
      "care - [compound] - health\n",
      "0 18 1101\n",
      "Electronic Medical Record ( EMR ) have establish itself as a valuable resource for large scale analysis of health datum .\n",
      "data - [compound] - health\n",
      "2 8 1112\n",
      "the propose MCLDA model assume that a latent health status group structure be responsible for the observe co-occurrence among diagnosis , medication , and contextual information .\n",
      "structure - [compound] - health\n",
      "3 28 80\n",
      "this study seek to identify case of undiagnosed dementia by develop and validate a weakly supervise machine-learning approach that incorporate the analysis of both structured and unstructured electronic health record ( ehr ) data.methodsa topic modeling approach that include latent Dirichlet allocation , stable topic extraction , and random sampling be apply to VHA ehr .\n",
      "record - [compound] - health\n",
      "0 12 32\n",
      "Diabetes and its complication have be recognize worldwide as a major public health threat .\n",
      "threat - [compound] - health\n",
      "0 14 627\n",
      "obstetric electronic medical record ( emr ) contain massive amount of medical datum and health information .\n",
      "information - [compound] - health\n",
      "1 27 1037\n",
      "the symptom or characteristic of illness course necessary to develop reliable predictor be not available in code billing datum , but may be present in narrative electronic health record ( ehr ) discharge summary .\n",
      "record - [compound] - health\n",
      "2 23 1402\n",
      "to this end , in this paper , we propose a new approach for risk stratification by explore a large volume of electronic health record ( ehr ) in a unsupervised fashion .\n",
      "records - [compound] - health\n",
      "0 12 1624\n",
      "the recent year have see a surge in the implementation of electronic health care record .\n",
      "records - [compound] - health\n",
      "5 12 1624\n",
      "in we research , we partition graph from term gather from electronic health record .\n",
      "records - [compound] - health\n",
      "#################### ('clinical', 139.72) ####################\n",
      "6 65 722\n",
      "a total of 33.3 % ( 12/36 ) patient positive for hpv-16 have cervical intraepithelial neoplasia ( cin ) 2 or a worse result , which be significantly higher than the prevalence of cin2 of 1.8 % ( 8/455 ) in patient negative for hpv-16 ( p < 0.001 ) , while no significant association be identify for other genotype in term of genotype and clinical progress .\n",
      "progress - [amod] - clinical\n",
      "11 24 722\n",
      "statistical and lda analysis produce consistent result regard the association between persistent infection of hpv-16 , old age and long infection period with a clinical progression of cin2 or worse .\n",
      "progression - [amod] - clinical\n",
      "0 2 1566\n",
      "the expand clinical information provide by the advent of electronic medical record offer a exciting opportunity to substantially improve the quality of health care .\n",
      "information - [amod] - clinical\n",
      "1 3 1566\n",
      "by examine the clinical observation ( such as diagnosis , risk factor , and medication ) mention in longitudinal emr , we can use patient ' medical chronology to automatically predict the progression of they pathology .\n",
      "observations - [amod] - clinical\n",
      "2 26 1566\n",
      "in this paper , we present a novel probabilistic model which jointly learn how to ( 1 ) group patient base on the similarity between they clinical observation as well as how to ( 2 ) predict the way a new patient 's clinical observation might evolve in the future .\n",
      "observations - [amod] - clinical\n",
      "2 43 1566\n",
      "in this paper , we present a novel probabilistic model which jointly learn how to ( 1 ) group patient base on the similarity between they clinical observation as well as how to ( 2 ) predict the way a new patient 's clinical observation might evolve in the future .\n",
      "observations - [amod] - clinical\n",
      "3 16 1566\n",
      "we show that we model can be use to not only track how a patient 's clinical finding might change over time , but to also identify which patient be due for preventative visit .\n",
      "findings - [amod] - clinical\n",
      "4 25 1566\n",
      "in addition , we model have the potential to improve the quality of over-all patient care in practice by predict the most likely set of clinical observation at a arbitrary point in the future .\n",
      "observations - [amod] - clinical\n",
      "1 14 1112\n",
      "to gain a better understanding of big healthcare datum and to develop better data-driven clinical decision support system , we propose a novel multiple - channel latent dirichlet allocation ( mclda ) approach for modeling diagnosis , medication , and contextual information in healthcare datum .\n",
      "systems - [amod] - clinical\n",
      "8 12 1112\n",
      "thus , mclda represent a promising approach to modeling healthcare datum for clinical decision support .\n",
      "support - [amod] - clinical\n",
      "0 8 2304\n",
      "induction of common knowledge or regularity from large-scale clinical datum be a vital task for chinese medicine ( cm ) .\n",
      "data - [amod] - clinical\n",
      "1 36 2304\n",
      "in this paper , we propose a data mining method , call the Symptom-Herb-Diagnosis topic ( shot ) model , to automatically extract the common relationship among symptom , herb combination and diagnosis from large-scale cm clinical datum .\n",
      "data - [amod] - clinical\n",
      "6 13 2304\n",
      "furthermore , the result demonstrate that this method be helpful for generate cm clinical guideline for t2dm base on structured collect clinical datum .\n",
      "guidelines - [amod] - clinical\n",
      "6 21 2304\n",
      "furthermore , the result demonstrate that this method be helpful for generate cm clinical guideline for t2dm base on structured collect clinical datum .\n",
      "data - [amod] - clinical\n",
      "4 32 1037\n",
      "the cohort be randomly split to derive a training ( 70 % ) and testing ( 30 % ) data set , and we train separate support vector machine model for baseline clinical feature alone , baseline feature plus common individual word and the above plus topic identify from the 75-topic LDA model .\n",
      "features - [amod] - clinical\n",
      "9 21 1037\n",
      "topic modeling and related approach offer the potential to improve prediction use ehr , if generalizability can be establish in other clinical cohort .\n",
      "cohorts - [amod] - clinical\n",
      "0 0 1446\n",
      "clinical pathway ( cp ) analysis play a important role in health-care management in ensure specialize , standardized , normalize and sophisticated therapy procedure for individual patient .\n",
      "pathway - [amod] - Clinical\n",
      "0 18 1402\n",
      "background and objective : risk stratification aim to provide physician with the accurate assessment of a patient 's clinical risk such that a individualized prevention or management strategy can be develop and deliver .\n",
      "risk - [amod] - clinical\n",
      "1 39 1402\n",
      "exist risk stratification technique mainly focus on predict the overall risk of a individual patient in a supervised manner , and , at the cohort level , often offer little insight beyond a flat score-based segmentation from the label clinical dataset .\n",
      "dataset - [amod] - clinical\n",
      "4 6 1402\n",
      "the propose PRSM recognize a patient clinical state as a probabilistic combination of latent sub-profile , and generate sub-profile-specific risk tier of patient from they ehr in a fully unsupervised fashion .\n",
      "state - [amod] - clinical\n",
      "7 12 1402\n",
      "result : we verify the effectiveness of the propose approach on a clinical dataset contain 3463 coronary heart disease ( chd ) patient instance .\n",
      "dataset - [amod] - clinical\n",
      "0 9 1129\n",
      "in healthcare organizational setting , the design of a clinical pathway ( cp ) be challenge since patient follow a particular pathway may have not only one single first-diagnosis but also several typical comorbidity , and thus it require different discipline involve to put together they partial knowledge about the overall pathway .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathway - [amod] - clinical\n",
      "1 23 1129\n",
      "although many datum mining technique have be propose to discover latent treatment information for cp analysis and reconstruction from a large volume of clinical datum , they be specific to extract nontrivial information about the therapy and treatment of the first-diagnosis .\n",
      "data - [amod] - clinical\n",
      "7 11 1129\n",
      "we verify the effectiveness of the propose model on a real clinical dataset contain 12,120 patient trace , which pertain to the unstable angina cp .\n",
      "dataset - [amod] - clinical\n",
      "#################### ('treatment', 99.44) ####################\n",
      "4 19 1101\n",
      "this topic modeling help to understand the constitution of patient disease and offer a tool for better planning of treatment .\n",
      "treatment - [case] - of\n",
      "planning - [nmod:of] - treatment\n",
      "3 12 2304\n",
      "we apply the SHDT model to discover the common cm diagnosis and treatment knowledge for type 2 diabetes mellitus ( t2dm ) use 3 238 inpatient case .\n",
      "knowledge - [compound] - treatment\n",
      "4 5 2304\n",
      "we obtain meaningful diagnosis and treatment topic ( cluster ) from the datum , which clinically indicate some important medical group correspond to comorbidity disease ( e.g. , heart disease and diabetic kidney disease in t2dm inpatient ) .\n",
      "topics - [compound] - treatment\n",
      "3 14 1446\n",
      "more specifically , we develop a probabilistic topic model to link patient feature and treatment behavior together to mine treatment pattern hide in emr .\n",
      "behaviors - [compound] - treatment\n",
      "3 19 1446\n",
      "more specifically , we develop a probabilistic topic model to link patient feature and treatment behavior together to mine treatment pattern hide in emr .\n",
      "patterns - [compound] - treatment\n",
      "4 1 1446\n",
      "discover treatment pattern , as actionable knowledge represent the best practice for most patient in most time of they treatment process , form the backbone of cp , and can be exploit to help physician better understand they specialty and learn from previous experience for cp analysis and improvement .\n",
      "patterns - [compound] - treatment\n",
      "4 19 1446\n",
      "discover treatment pattern , as actionable knowledge represent the best practice for most patient in most time of they treatment process , form the backbone of cp , and can be exploit to help physician better understand they specialty and learn from previous experience for cp analysis and improvement .\n",
      "processes - [compound] - treatment\n",
      "5 23 1446\n",
      "experimental result on a real collection of 985 emr collect from a chinese hospital show that the propose approach can effectively identify meaningful treatment pattern from emr .\n",
      "patterns - [compound] - treatment\n",
      "1 11 1129\n",
      "although many datum mining technique have be propose to discover latent treatment information for cp analysis and reconstruction from a large volume of clinical datum , they be specific to extract nontrivial information about the therapy and treatment of the first-diagnosis .\n",
      "information - [compound] - treatment\n",
      "1 37 1129\n",
      "although many datum mining technique have be propose to discover latent treatment information for cp analysis and reconstruction from a large volume of clinical datum , they be specific to extract nontrivial information about the therapy and treatment of the first-diagnosis .\n",
      "information - [nmod:about] - treatment\n",
      "therapy - [conj:and] - treatment\n",
      "2 7 1129\n",
      "the influence of comorbidity on adopt essential treatment be crucial for a pathway but have seldom be explore .\n",
      "treatments - [amod] - essential\n",
      "adopting - [dobj] - treatments\n",
      "3 6 1129\n",
      "this study propose to extract latent treatment pattem that characterize essential treatment for both first-diagnosis and typical comorbidity from the execution datum of a pathway .\n",
      "pattems - [compound] - treatment\n",
      "3 11 1129\n",
      "this study propose to extract latent treatment pattem that characterize essential treatment for both first-diagnosis and typical comorbidity from the execution datum of a pathway .\n",
      "treatments - [amod] - essential\n",
      "characterize - [dobj] - treatments\n",
      "treatments - [nmod:for] - first-diagnosis\n",
      "treatments - [nmod:for] - comorbidities\n",
      "4 12 1129\n",
      "in particular , we propose a generative statistical model to extract underlie treatment pattern , unveil the latent association between diagnosis label ( include both first-diagnosis and comorbidity ) and treatment , and compute the contribution of comorbidity in these pattem .\n",
      "patterns - [compound] - treatment\n",
      "4 30 1129\n",
      "in particular , we propose a generative statistical model to extract underlie treatment pattern , unveil the latent association between diagnosis label ( include both first-diagnosis and comorbidity ) and treatment , and compute the contribution of comorbidity in these pattem .\n",
      "associations - [nmod:between] - treatments\n",
      "labels - [conj:and] - treatments\n",
      "6 7 1129\n",
      "it first generate a set of latent treatment pattern from diagnosis label , follow by sampling treatment from each pattern .\n",
      "patterns - [compound] - treatment\n",
      "6 16 1129\n",
      "it first generate a set of latent treatment pattern from diagnosis label , follow by sampling treatment from each pattern .\n",
      "treatments - [case] - by\n",
      "treatments - [compound] - sampling\n",
      "followed - [nmod:by] - treatments\n",
      "treatments - [nmod:from] - pattern\n",
      "8 1 1129\n",
      "three treatment pattern be discover from datum , indicate latent correlation between comorbidity and treatment in the pathway .\n",
      "patterns - [compound] - treatment\n",
      "8 14 1129\n",
      "three treatment pattern be discover from datum , indicate latent correlation between comorbidity and treatment in the pathway .\n",
      "correlations - [nmod:between] - treatments\n",
      "comorbidities - [conj:and] - treatments\n",
      "9 10 1129\n",
      "in addition , a possible medical application in term of treatment recommendation be provide to illustrate the potential of the propose model .\n",
      "recommendation - [compound] - treatment\n",
      "10 12 1129\n",
      "experimental result indicate that we approach can discover not only meaningful latent treatment pattern exhibit comorbidity focus , but also implicit change of treatment of first-diagnosis due to the incorporation of typical comorbidity potentially .\n",
      "patterns - [compound] - treatment\n",
      "10 23 1129\n",
      "experimental result indicate that we approach can discover not only meaningful latent treatment pattern exhibit comorbidity focus , but also implicit change of treatment of first-diagnosis due to the incorporation of typical comorbidity potentially .\n",
      "treatments - [case] - of\n",
      "changes - [nmod:of] - treatments\n",
      "treatments - [nmod:of] - first-diagnosis\n",
      "8 19 174\n",
      "the majority of theme ( n = 67 [ 60 % ] ) focus on discussion relate to as treatment .\n",
      "treatment - [case] - to\n",
      "treatment - [amod] - AS\n",
      "related - [nmod:to] - treatment\n",
      "10 4 174\n",
      "in discussion regard as treatment , most topic involve biologic , and most subtheme involve side effect ( e.g. , fatigue , allergic reaction ) , biologic treatment attribute ( e.g. , dosing , frequency ) , and concern about use of biologic ( e.g. , increase cancer risk ) .\n",
      "treatment - [case] - regarding\n",
      "treatment - [amod] - AS\n",
      "discussions - [nmod:regarding] - treatment\n",
      "10 27 174\n",
      "in discussion regard as treatment , most topic involve biologic , and most subtheme involve side effect ( e.g. , fatigue , allergic reaction ) , biologic treatment attribute ( e.g. , dosing , frequency ) , and concern about use of biologic ( e.g. , increase cancer risk ) .\n",
      "attributes - [compound] - treatment\n",
      "1 13 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "methods - [compound] - treatment\n",
      "#################### ('diagnosis', 86.78) ####################\n",
      "1 8 1566\n",
      "by examine the clinical observation ( such as diagnosis , risk factor , and medication ) mention in longitudinal emr , we can use patient ' medical chronology to automatically predict the progression of they pathology .\n",
      "diagnoses - [punct] - -LRB-\n",
      "diagnoses - [case] - such\n",
      "observations - [nmod:such_as] - diagnoses\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [conj:and] - factors\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [cc] - and\n",
      "diagnoses - [conj:and] - medications\n",
      "diagnoses - [punct] - -RRB-\n",
      "2 7 1101\n",
      "a medical record contain diagnostic information ( diagnosis code ) , procedure perform ( procedure code ) and admission detail .\n",
      "codes - [compound] - diagnosis\n",
      "3 36 1101\n",
      "traditional topic model , such as latent dirichlet allocation ( lda ) and hierarchical dirichlet process ( hdp ) , can be employ to discover disease topic from emr datum by treat patient as document and diagnosis code as word .\n",
      "codes - [compound] - diagnosis\n",
      "6 7 1101\n",
      "we be motivate by the fact that diagnosis code be connect in the form of icd-10 tree structure which present semantic relationship between code .\n",
      "codes - [compound] - diagnosis\n",
      "9 9 1101\n",
      "furthermore , since procedure code be often correlate with diagnosis code , we develop the correspondence wddcrf ( corr-wddcrf ) to explore conditional relationship of procedure code for a give disease pattern .\n",
      "codes - [compound] - diagnosis\n",
      "0 17 1112\n",
      "information and communication technology have enable healthcare institution to accumulate large amount of healthcare datum that include diagnosis , medication , and additional contextual information such as patient demographic .\n",
      "include - [dobj] - diagnoses\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [conj:and] - medications\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [cc] - and\n",
      "diagnoses - [conj:and] - information\n",
      "1 35 1112\n",
      "to gain a better understanding of big healthcare datum and to develop better data-driven clinical decision support system , we propose a novel multiple - channel latent dirichlet allocation ( mclda ) approach for modeling diagnosis , medication , and contextual information in healthcare datum .\n",
      "diagnoses - [case] - for\n",
      "diagnoses - [compound] - modeling\n",
      "approach - [nmod:for] - diagnoses\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [conj:and] - medications\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [cc] - and\n",
      "diagnoses - [conj:and] - information\n",
      "2 19 1112\n",
      "the propose MCLDA model assume that a latent health status group structure be responsible for the observe co-occurrence among diagnosis , medication , and contextual information .\n",
      "diagnoses - [case] - among\n",
      "co-occurrences - [nmod:among] - diagnoses\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [conj:and] - medications\n",
      "diagnoses - [punct] - ,\n",
      "diagnoses - [cc] - and\n",
      "diagnoses - [conj:and] - information\n",
      "5 10 1112\n",
      "moreover , MCLDA be able to identify the pairing between diagnosis and medication in a record base on the assign latent group .\n",
      "diagnoses - [case] - between\n",
      "pairing - [nmod:between] - diagnoses\n",
      "diagnoses - [cc] - and\n",
      "diagnoses - [conj:and] - medications\n",
      "6 10 1112\n",
      "MCLDA can also be employ to predict miss medication or diagnosis give partial record .\n",
      "predict - [dobj] - diagnoses\n",
      "medications - [conj:or] - diagnoses\n",
      "7 35 1112\n",
      "we evaluation result also show that , in most case , MCLDA outperform alternative method such as logistic regression and the k-nearest-neighbor ( knn ) model for two prediction task , i.e. , medication and diagnosis prediction .\n",
      "prediction - [compound] - diagnosis\n",
      "8 18 80\n",
      "ConclusionsDementia be underdiagnosed , and thus , icd code alone can not serve as a gold standard for diagnosis .\n",
      "diagnosis - [case] - for\n",
      "standard - [nmod:for] - diagnosis\n",
      "10 20 80\n",
      "the study be one of the first to utilize both structured and unstructured ehr to develop risk score for the diagnosis of dementia .\n",
      "diagnosis - [case] - for\n",
      "diagnosis - [det] - the\n",
      "scores - [nmod:for] - diagnosis\n",
      "diagnosis - [nmod:of] - dementia\n",
      "1 4 627\n",
      "the information extraction and diagnosis assistant of obstetric emr be of great significance in improve the fertility level of the population .\n",
      "assistants - [compound] - diagnosis\n",
      "2 2 627\n",
      "the admit diagnosis in the first course record of the emr be reason from various source , such as chief complaint , auxiliary examination , and physical examination .\n",
      "diagnosis - [det] - The\n",
      "diagnosis - [amod] - admitting\n",
      "reasoned - [nsubjpass] - diagnosis\n",
      "diagnosis - [nmod:in] - record\n",
      "3 4 627\n",
      "this paper treat the diagnosis assistant as a multilabel classification task base on the analysis of obstetric emr .\n",
      "assistant - [compound] - diagnosis\n",
      "4 56 627\n",
      "the latent Dirichlet allocation ( lda ) topic and the word vector be use as feature and the four multilabel classification method , bp-mll ( backpropagation multilabel learning ) , rakel ( random k labelset ) , mlknn ( multilabel k-nearest neighbor ) , and cc ( chain classifier ) , be utilize to build the diagnosis assistant model .\n",
      "models - [compound] - diagnosis\n",
      "6 4 627\n",
      "the result of the diagnosis assistant can be introduce as a supplementary learning method for medical student .\n",
      "assistant - [compound] - diagnosis\n",
      "0 25 415\n",
      "multiple Kernel Learning with adaptive Neuro-Fuzzy Inference System ( mkl with anfis ) base deep learning method be propose in this paper for heart disease diagnosis .\n",
      "diagnosis - [case] - for\n",
      "diagnosis - [compound] - heart\n",
      "diagnosis - [compound] - disease\n",
      "proposed - [nmod:for] - diagnosis\n",
      "1 32 2304\n",
      "in this paper , we propose a data mining method , call the Symptom-Herb-Diagnosis topic ( shot ) model , to automatically extract the common relationship among symptom , herb combination and diagnosis from large-scale cm clinical datum .\n",
      "relationships - [nmod:among] - diagnoses\n",
      "symptoms - [conj:and] - diagnoses\n",
      "3 10 2304\n",
      "we apply the SHDT model to discover the common cm diagnosis and treatment knowledge for type 2 diabetes mellitus ( t2dm ) use 3 238 inpatient case .\n",
      "diagnosis - [det] - the\n",
      "diagnosis - [amod] - common\n",
      "diagnosis - [compound] - CM\n",
      "discover - [dobj] - diagnosis\n",
      "diagnosis - [cc] - and\n",
      "diagnosis - [conj:and] - knowledge\n",
      "diagnosis - [nmod:for] - mellitus\n",
      "4 3 2304\n",
      "we obtain meaningful diagnosis and treatment topic ( cluster ) from the datum , which clinically indicate some important medical group correspond to comorbidity disease ( e.g. , heart disease and diabetic kidney disease in t2dm inpatient ) .\n",
      "diagnosis - [amod] - meaningful\n",
      "obtained - [dobj] - diagnosis\n",
      "diagnosis - [cc] - and\n",
      "diagnosis - [conj:and] - topics\n",
      "2 19 1037\n",
      "we identify a cohort of individual admit to a psychiatric inpatient unit between 1994 and 2012 with a principal diagnosis of major depressive disorder , and extract inpatient psychiatric discharge narrative note .\n",
      "diagnosis - [case] - with\n",
      "diagnosis - [det] - a\n",
      "diagnosis - [amod] - principal\n",
      "admitted - [nmod:with] - diagnosis\n",
      "diagnosis - [nmod:of] - disorder\n",
      "4 20 1129\n",
      "in particular , we propose a generative statistical model to extract underlie treatment pattern , unveil the latent association between diagnosis label ( include both first-diagnosis and comorbidity ) and treatment , and compute the contribution of comorbidity in these pattem .\n",
      "labels - [compound] - diagnosis\n",
      "5 12 1129\n",
      "the propose model extend latent Dirichlet allocation with a additional layer for diagnosis modeling .\n",
      "modeling - [compound] - diagnosis\n",
      "6 10 1129\n",
      "it first generate a set of latent treatment pattern from diagnosis label , follow by sampling treatment from each pattern .\n",
      "labels - [compound] - diagnosis\n",
      "9 13 338\n",
      "the patient-related domain include the category of the patient profile , symptom , diagnosis , and pathogenesis .\n",
      "categories - [nmod:of] - diagnosis\n",
      "profile - [conj:and] - diagnosis\n",
      "12 78 338\n",
      "symptom ( Cohen d = 1.58 , Delta u = 0.216 , t = 229.75 , and p < .001 ) be more often mention by patient with acute disease , whereas communication skill ( Cohen d = -0.29 , Delta u = -0.038 , t = -42.01 , and p < .001 ) , financing ( Cohen d = -0.68 , Delta u = -0.098 , t = -99.26 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -0.55 , Delta u = -0.078 , t = -80.09 , and p < .001 ) be more often mention by patient with chronic disease .\n",
      "skills - [conj:and] - diagnosis\n",
      "mentioned - [nsubjpass] - diagnosis\n",
      "diagnosis - [cc] - and\n",
      "diagnosis - [conj:and] - pathogenesis\n",
      "diagnosis - [dep] - d\n",
      "diagnosis - [dep] - P\n",
      "14 81 338\n",
      "meanwhile , patient with serious disease be more interested in medical competence ( Cohen d = -0.99 , Delta u = -0.165 , t = -32.58 , and p < .001 ) , medical advice and prescription ( Cohen d = -0.65 , Delta u = -0.082 , t = -21.45 , and p < .001 ) , financing ( Cohen d = -0.26 , Delta u = -0.018 , t = -8.45 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -1.55 , Delta u = -0.229 , t = -50.93 , and p < .001 ) .\n",
      "interested - [nmod:in] - diagnosis\n",
      "competence - [conj:and] - diagnosis\n",
      "diagnosis - [cc] - and\n",
      "diagnosis - [conj:and] - pathogenesis\n",
      "diagnosis - [dep] - d\n",
      "diagnosis - [dep] - P\n",
      "1 11 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "information - [nmod:including] - diagnosis\n",
      "information - [conj:and] - diagnosis\n",
      "#################### ('disease', 81.07) ####################\n",
      "3 25 1101\n",
      "traditional topic model , such as latent dirichlet allocation ( lda ) and hierarchical dirichlet process ( hdp ) , can be employ to discover disease topic from emr datum by treat patient as document and diagnosis code as word .\n",
      "topics - [compound] - disease\n",
      "4 10 1101\n",
      "this topic modeling help to understand the constitution of patient disease and offer a tool for better planning of treatment .\n",
      "diseases - [case] - of\n",
      "diseases - [compound] - patient\n",
      "constitution - [nmod:of] - diseases\n",
      "5 33 1101\n",
      "in this paper , we propose a novel and flexible hierarchical bayesian nonparametric model , the word distance dependent chinese restaurant franchise ( wddcrf ) , which incorporate word-to-word distance to discover semantically-coherent disease topic .\n",
      "topics - [compound] - disease\n",
      "9 30 1101\n",
      "furthermore , since procedure code be often correlate with diagnosis code , we develop the correspondence wddcrf ( corr-wddcrf ) to explore conditional relationship of procedure code for a give disease pattern .\n",
      "pattern - [compound] - disease\n",
      "11 12 1101\n",
      "we evaluate the propose model on two real-world medical dataset - polyvascular disease and acute myocardial infarction disease .\n",
      "disease - [amod] - PolyVascular\n",
      "datasets - [dep] - disease\n",
      "disease - [cc] - and\n",
      "disease - [conj:and] - disease\n",
      "11 17 1101\n",
      "we evaluate the propose model on two real-world medical dataset - polyvascular disease and acute myocardial infarction disease .\n",
      "disease - [amod] - Acute\n",
      "disease - [amod] - Myocardial\n",
      "disease - [compound] - Infarction\n",
      "datasets - [dep] - disease\n",
      "disease - [conj:and] - disease\n",
      "13 3 1101\n",
      "we also use disease topic proportion as new feature and show that use feature from the corr-wddcrf outperform the baseline on 14-day readmission prediction .\n",
      "proportions - [compound] - disease\n",
      "0 24 415\n",
      "multiple Kernel Learning with adaptive Neuro-Fuzzy Inference System ( mkl with anfis ) base deep learning method be propose in this paper for heart disease diagnosis .\n",
      "diagnosis - [compound] - disease\n",
      "2 9 415\n",
      "mkl method be use to divide parameter between heart disease patient and normal individual .\n",
      "patients - [compound] - disease\n",
      "3 17 415\n",
      "the result obtain from the mkl method be give to the ANFIS classifier to classify the heart disease and healthy patient .\n",
      "disease - [det] - the\n",
      "disease - [compound] - heart\n",
      "classify - [dobj] - disease\n",
      "disease - [cc] - and\n",
      "disease - [conj:and] - patients\n",
      "4 24 2304\n",
      "we obtain meaningful diagnosis and treatment topic ( cluster ) from the datum , which clinically indicate some important medical group correspond to comorbidity disease ( e.g. , heart disease and diabetic kidney disease in t2dm inpatient ) .\n",
      "diseases - [case] - to\n",
      "diseases - [compound] - comorbidity\n",
      "corresponding - [nmod:to] - diseases\n",
      "diseases - [dep] - disease\n",
      "diseases - [dep] - diseases\n",
      "4 29 2304\n",
      "we obtain meaningful diagnosis and treatment topic ( cluster ) from the datum , which clinically indicate some important medical group correspond to comorbidity disease ( e.g. , heart disease and diabetic kidney disease in t2dm inpatient ) .\n",
      "disease - [punct] - -LRB-\n",
      "disease - [dep] - e.g.\n",
      "disease - [punct] - ,\n",
      "disease - [compound] - heart\n",
      "diseases - [dep] - disease\n",
      "disease - [cc] - and\n",
      "disease - [conj:and] - diseases\n",
      "disease - [nmod:in] - inpatients\n",
      "disease - [punct] - -RRB-\n",
      "4 33 2304\n",
      "we obtain meaningful diagnosis and treatment topic ( cluster ) from the datum , which clinically indicate some important medical group correspond to comorbidity disease ( e.g. , heart disease and diabetic kidney disease in t2dm inpatient ) .\n",
      "diseases - [amod] - diabetic\n",
      "diseases - [compound] - kidney\n",
      "diseases - [dep] - diseases\n",
      "disease - [conj:and] - diseases\n",
      "6 40 1037\n",
      "the 75-topic LDA model include topic link to psychiatric symptom ( suicide , severe depression , anxiety , trauma , eating/weight and panic ) and major depressive disorder comorbidity ( infection , postpartum , brain tumor , diarrhea and pulmonary disease ) .\n",
      "disease - [amod] - pulmonary\n",
      "comorbidities - [dep] - disease\n",
      "infection - [conj:and] - disease\n",
      "6 48 1402\n",
      "in addition , we present a extension of PRSM , call weakly supervise prsm ( ws-prsm ) by incorporate minimum prior information into the model , in order to improve the risk stratification accuracy , and to make we model highly portable to risk stratification task of various disease .\n",
      "diseases - [case] - of\n",
      "diseases - [amod] - various\n",
      "tasks - [nmod:of] - diseases\n",
      "7 18 1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : we verify the effectiveness of the propose approach on a clinical dataset contain 3463 coronary heart disease ( chd ) patient instance .\n",
      "disease - [nummod] - 3463\n",
      "disease - [amod] - coronary\n",
      "disease - [compound] - heart\n",
      "instances - [compound] - disease\n",
      "disease - [appos] - CHD\n",
      "11 20 1402\n",
      "in addition , the unsupervised nature of we model make they highly portable to the risk stratification task of various disease .\n",
      "diseases - [case] - of\n",
      "diseases - [amod] - various\n",
      "tasks - [nmod:of] - diseases\n",
      "9 17 174\n",
      "other theme , include the psychological impact of as , reporting of medical literature , and as disease consequence , account for the remain 40 % ( n = 45 ) .\n",
      "consequences - [compound] - disease\n",
      "12 29 338\n",
      "symptom ( Cohen d = 1.58 , Delta u = 0.216 , t = 229.75 , and p < .001 ) be more often mention by patient with acute disease , whereas communication skill ( Cohen d = -0.29 , Delta u = -0.038 , t = -42.01 , and p < .001 ) , financing ( Cohen d = -0.68 , Delta u = -0.098 , t = -99.26 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -0.55 , Delta u = -0.078 , t = -80.09 , and p < .001 ) be more often mention by patient with chronic disease .\n",
      "diseases - [case] - with\n",
      "diseases - [amod] - acute\n",
      "patients - [nmod:with] - diseases\n",
      "12 109 338\n",
      "symptom ( Cohen d = 1.58 , Delta u = 0.216 , t = 229.75 , and p < .001 ) be more often mention by patient with acute disease , whereas communication skill ( Cohen d = -0.29 , Delta u = -0.038 , t = -42.01 , and p < .001 ) , financing ( Cohen d = -0.68 , Delta u = -0.098 , t = -99.26 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -0.55 , Delta u = -0.078 , t = -80.09 , and p < .001 ) be more often mention by patient with chronic disease .\n",
      "diseases - [case] - with\n",
      "diseases - [amod] - chronic\n",
      "patients - [nmod:with] - diseases\n",
      "13 3 338\n",
      "patient with mild disease be more interested in medical ethic ( Cohen d = 0.25 , Delta u 0.039 , t = 8.33 , and p < .001 ) , operation process ( Cohen d = 0.57 , Delta u 0.060 , t = 18.75 , and p < .001 ) , patient profile ( Cohen d = 1.19 , Delta u 0.132 , t = 39.33 , and p < .001 ) , and symptom ( Cohen d = 1.91 , Delta u = 0.274 , t = 62.82 , and p < .001 ) .\n",
      "diseases - [case] - with\n",
      "diseases - [amod] - mild\n",
      "Patients - [nmod:with] - diseases\n",
      "14 5 338\n",
      "meanwhile , patient with serious disease be more interested in medical competence ( Cohen d = -0.99 , Delta u = -0.165 , t = -32.58 , and p < .001 ) , medical advice and prescription ( Cohen d = -0.65 , Delta u = -0.082 , t = -21.45 , and p < .001 ) , financing ( Cohen d = -0.26 , Delta u = -0.018 , t = -8.45 , and p < .001 ) , and diagnosis and pathogenesis ( Cohen d = -1.55 , Delta u = -0.229 , t = -50.93 , and p < .001 ) .\n",
      "diseases - [case] - with\n",
      "diseases - [amod] - serious\n",
      "patients - [nmod:with] - diseases\n",
      "17 14 338\n",
      "furthermore , the mining result reveal marked difference in patient ' interest across different disease type , socioeconomic development level , and hospital level .\n",
      "types - [compound] - disease\n",
      "#################### ('risk', 79.0) ####################\n",
      "1 10 1566\n",
      "by examine the clinical observation ( such as diagnosis , risk factor , and medication ) mention in longitudinal emr , we can use patient ' medical chronology to automatically predict the progression of they pathology .\n",
      "factors - [compound] - risk\n",
      "9 29 80\n",
      "however , this study suggest that imperfect datum ( e.g. , icd code in combination with other ehr feature ) can serve as a silver standard to develop a risk model , apply that model to patient without dementia code , and then select a case-detection threshold .\n",
      "model - [compound] - risk\n",
      "10 16 80\n",
      "the study be one of the first to utilize both structured and unstructured ehr to develop risk score for the diagnosis of dementia .\n",
      "scores - [compound] - risk\n",
      "0 15 1037\n",
      "the ability to predict psychiatric readmission would facilitate the development of intervention to reduce this risk , a major driver of psychiatric health-care cost .\n",
      "risk - [det] - this\n",
      "reduce - [dobj] - risk\n",
      "8 15 1037\n",
      "inclusion of topic derive from narrative note allow more accurate discrimination of individual at high risk for psychiatric readmission in this cohort .\n",
      "risk - [case] - at\n",
      "risk - [amod] - high\n",
      "discrimination - [nmod:at] - risk\n",
      "risk - [nmod:for] - readmission\n",
      "0 4 1402\n",
      "background and objective : risk stratification aim to provide physician with the accurate assessment of a patient 's clinical risk such that a individualized prevention or management strategy can be develop and deliver .\n",
      "stratification - [compound] - Risk\n",
      "0 19 1402\n",
      "background and objective : risk stratification aim to provide physician with the accurate assessment of a patient 's clinical risk such that a individualized prevention or management strategy can be develop and deliver .\n",
      "risk - [case] - of\n",
      "risk - [nmod:poss] - patient\n",
      "risk - [amod] - clinical\n",
      "assessment - [nmod:of] - risk\n",
      "1 1 1402\n",
      "exist risk stratification technique mainly focus on predict the overall risk of a individual patient in a supervised manner , and , at the cohort level , often offer little insight beyond a flat score-based segmentation from the label clinical dataset .\n",
      "techniques - [compound] - risk\n",
      "1 10 1402\n",
      "exist risk stratification technique mainly focus on predict the overall risk of a individual patient in a supervised manner , and , at the cohort level , often offer little insight beyond a flat score-based segmentation from the label clinical dataset .\n",
      "risk - [det] - the\n",
      "risk - [amod] - overall\n",
      "predicting - [dobj] - risk\n",
      "risk - [nmod:of] - patient\n",
      "2 14 1402\n",
      "to this end , in this paper , we propose a new approach for risk stratification by explore a large volume of electronic health record ( ehr ) in a unsupervised fashion .\n",
      "stratification - [compound] - risk\n",
      "3 17 1402\n",
      "method : along this line , this paper propose a novel probabilistic topic modeling framework call probabilistic risk stratification model ( prsm ) base on latent Dirichlet allocation ( lda ) .\n",
      "model - [compound] - risk\n",
      "4 19 1402\n",
      "the propose PRSM recognize a patient clinical state as a probabilistic combination of latent sub-profile , and generate sub-profile-specific risk tier of patient from they ehr in a fully unsupervised fashion .\n",
      "tiers - [compound] - risk\n",
      "6 31 1402\n",
      "in addition , we present a extension of PRSM , call weakly supervise prsm ( ws-prsm ) by incorporate minimum prior information into the model , in order to improve the risk stratification accuracy , and to make we model highly portable to risk stratification task of various disease .\n",
      "accuracy - [compound] - risk\n",
      "6 43 1402\n",
      "in addition , we present a extension of PRSM , call weakly supervise prsm ( ws-prsm ) by incorporate minimum prior information into the model , in order to improve the risk stratification accuracy , and to make we model highly portable to risk stratification task of various disease .\n",
      "risk - [nsubj:xsubj] - models\n",
      "risk - [mark] - to\n",
      "portable - [xcomp] - risk\n",
      "risk - [dobj] - tasks\n",
      "8 10 1402\n",
      "both prsm and ws-prsm be compare with two established supervised risk stratification algorithm , i.e. , logistic regression and support vector machine , and show the effectiveness of we model in risk stratification of chd in term of the Area under the receiver operating characteristic curve ( auc ) analysis .\n",
      "algorithms - [compound] - risk\n",
      "8 31 1402\n",
      "both prsm and ws-prsm be compare with two established supervised risk stratification algorithm , i.e. , logistic regression and support vector machine , and show the effectiveness of we model in risk stratification of chd in term of the Area under the receiver operating characteristic curve ( auc ) analysis .\n",
      "stratification - [compound] - risk\n",
      "9 24 1402\n",
      "as well , in comparison with prsm , ws-prsm have over 2 % performance gain , on the experimental dataset , demonstrate that incorporate risk score knowledge as prior information can improve the performance in risk stratification .\n",
      "incorporating - [dobj] - risk\n",
      "risk - [acl] - scoring\n",
      "9 35 1402\n",
      "as well , in comparison with prsm , ws-prsm have over 2 % performance gain , on the experimental dataset , demonstrate that incorporate risk score knowledge as prior information can improve the performance in risk stratification .\n",
      "stratification - [compound] - risk\n",
      "10 12 1402\n",
      "conclusion : experimental result reveal that we model achieve competitive performance in risk stratification in comparison with exist supervised approach .\n",
      "stratification - [compound] - risk\n",
      "11 15 1402\n",
      "in addition , the unsupervised nature of we model make they highly portable to the risk stratification task of various disease .\n",
      "tasks - [compound] - risk\n",
      "12 6 1402\n",
      "moreover , patient sub-profile and sub-profile-specific risk tier generate by we model be coherent and informative , and provide significant potential to be explore for the further task , such as patient cohort analysis .\n",
      "tiers - [compound] - risk\n",
      "13 12 1402\n",
      "we hypothesize that the propose framework can readily meet the demand for risk stratification from a large volume of ehr in a open-ended fashion .\n",
      "stratification - [compound] - risk\n",
      "10 48 174\n",
      "in discussion regard as treatment , most topic involve biologic , and most subtheme involve side effect ( e.g. , fatigue , allergic reaction ) , biologic treatment attribute ( e.g. , dosing , frequency ) , and concern about use of biologic ( e.g. , increase cancer risk ) .\n",
      "risk - [amod] - increased\n",
      "risk - [compound] - cancer\n",
      "e.g. - [appos] - risk\n",
      "#################### ('record', 78.67) ####################\n",
      "0 11 1566\n",
      "the expand clinical information provide by the advent of electronic medical record offer a exciting opportunity to substantially improve the quality of health care .\n",
      "records - [case] - of\n",
      "records - [amod] - electronic\n",
      "records - [amod] - medical\n",
      "advent - [nmod:of] - records\n",
      "1 8 1101\n",
      "a hospital emr dataset typically consist of medical record of hospitalize patient .\n",
      "records - [case] - of\n",
      "records - [amod] - medical\n",
      "consists - [nmod:of] - records\n",
      "records - [nmod:of] - patients\n",
      "2 2 1101\n",
      "a medical record contain diagnostic information ( diagnosis code ) , procedure perform ( procedure code ) and admission detail .\n",
      "record - [det] - A\n",
      "record - [amod] - medical\n",
      "contains - [nsubj] - record\n",
      "3 12 1112\n",
      "use a real-world research testb that include one million healthcare insurance claim record , we investigate the utility of MCLDA .\n",
      "records - [nummod] - million\n",
      "records - [compound] - healthcare\n",
      "records - [compound] - insurance\n",
      "records - [compound] - claim\n",
      "includes - [dobj] - records\n",
      "5 15 1112\n",
      "moreover , MCLDA be able to identify the pairing between diagnosis and medication in a record base on the assign latent group .\n",
      "record - [case] - in\n",
      "record - [det] - a\n",
      "identify - [nmod:in] - record\n",
      "record - [nmod:based_on] - groups\n",
      "6 13 1112\n",
      "MCLDA can also be employ to predict miss medication or diagnosis give partial record .\n",
      "records - [case] - given\n",
      "records - [amod] - partial\n",
      "medications - [nmod:given] - records\n",
      "3 29 80\n",
      "this study seek to identify case of undiagnosed dementia by develop and validate a weakly supervise machine-learning approach that incorporate the analysis of both structured and unstructured electronic health record ( ehr ) data.methodsa topic modeling approach that include latent Dirichlet allocation , stable topic extraction , and random sampling be apply to VHA ehr .\n",
      "record - [case] - of\n",
      "record - [amod] - structured\n",
      "record - [amod] - unstructured\n",
      "record - [amod] - electronic\n",
      "record - [compound] - health\n",
      "analysis - [nmod:of] - record\n",
      "included - [nsubj] - record\n",
      "record - [appos] - EHR\n",
      "record - [dep] - approach\n",
      "record - [ref] - that\n",
      "record - [acl:relcl] - included\n",
      "6 25 80\n",
      "these score be validate in a subset of veteran without icd-9 dementia code ( n = 120 ) by expert in dementia who perform manual record review and achieve a high level of inter-rater agreement .\n",
      "reviews - [compound] - record\n",
      "2 10 32\n",
      "while many study currently use medical image and structured medical record , very limited effort have be dedicate to apply datum mining technique for unstructured textual medical record , such as admission and discharge record .\n",
      "records - [amod] - structured\n",
      "records - [amod] - medical\n",
      "use - [dobj] - records\n",
      "images - [conj:and] - records\n",
      "2 27 32\n",
      "while many study currently use medical image and structured medical record , very limited effort have be dedicate to apply datum mining technique for unstructured textual medical record , such as admission and discharge record .\n",
      "records - [case] - for\n",
      "records - [amod] - unstructured\n",
      "records - [amod] - textual\n",
      "records - [amod] - medical\n",
      "applying - [nmod:for] - records\n",
      "records - [punct] - ,\n",
      "records - [nmod:such_as] - admission\n",
      "records - [nmod:such_as] - records\n",
      "2 34 32\n",
      "while many study currently use medical image and structured medical record , very limited effort have be dedicate to apply datum mining technique for unstructured textual medical record , such as admission and discharge record .\n",
      "records - [compound] - discharge\n",
      "records - [nmod:such_as] - records\n",
      "admission - [conj:and] - records\n",
      "3 6 32\n",
      "moreover , the similarity among medical record that be overlook by exist approach could potentially improve the accuracy of prediction model .\n",
      "records - [case] - among\n",
      "records - [amod] - medical\n",
      "similarities - [nmod:among] - records\n",
      "overlooked - [nsubjpass] - records\n",
      "records - [ref] - that\n",
      "records - [acl:relcl] - overlooked\n",
      "5 10 32\n",
      "specifically , we first estimate the similarity between textual medical record after datum preprocessing , and then we perform selda-based diabetic complication topic mining base on similarity constraint .\n",
      "records - [case] - between\n",
      "records - [amod] - textual\n",
      "records - [amod] - medical\n",
      "similarity - [nmod:between] - records\n",
      "0 3 627\n",
      "obstetric electronic medical record ( emr ) contain massive amount of medical datum and health information .\n",
      "records - [amod] - Obstetric\n",
      "records - [amod] - electronic\n",
      "records - [amod] - medical\n",
      "contain - [nsubj] - records\n",
      "records - [appos] - EMRs\n",
      "2 7 627\n",
      "the admit diagnosis in the first course record of the emr be reason from various source , such as chief complaint , auxiliary examination , and physical examination .\n",
      "record - [case] - in\n",
      "record - [det] - the\n",
      "record - [amod] - first\n",
      "record - [compound] - course\n",
      "diagnosis - [nmod:in] - record\n",
      "record - [nmod:of] - EMR\n",
      "7 17 627\n",
      "additionally , the method can be use not only for obstetric emr but also for other medical record .\n",
      "records - [advmod] - also\n",
      "records - [case] - for\n",
      "records - [amod] - other\n",
      "records - [amod] - medical\n",
      "used - [nmod:for] - records\n",
      "1 28 1037\n",
      "the symptom or characteristic of illness course necessary to develop reliable predictor be not available in code billing datum , but may be present in narrative electronic health record ( ehr ) discharge summary .\n",
      "record - [case] - in\n",
      "record - [amod] - narrative\n",
      "record - [amod] - electronic\n",
      "record - [compound] - health\n",
      "present - [nmod:in] - record\n",
      "record - [appos] - EHR\n",
      "record - [dep] - summaries\n",
      "1 17 1446\n",
      "recently , with the rapid development of hospital information system , a large volume of electronic medical record ( emr ) have be produce , which provide a comprehensive source for cp analysis .\n",
      "records - [case] - of\n",
      "records - [amod] - electronic\n",
      "records - [amod] - medical\n",
      "volume - [nmod:of] - records\n",
      "records - [appos] - EMRs\n",
      "2 24 1402\n",
      "to this end , in this paper , we propose a new approach for risk stratification by explore a large volume of electronic health record ( ehr ) in a unsupervised fashion .\n",
      "records - [case] - of\n",
      "records - [amod] - electronic\n",
      "records - [compound] - health\n",
      "volume - [nmod:of] - records\n",
      "records - [appos] - EHRs\n",
      "0 14 1624\n",
      "the recent year have see a surge in the implementation of electronic health care record .\n",
      "records - [case] - of\n",
      "records - [amod] - electronic\n",
      "records - [compound] - health\n",
      "records - [compound] - care\n",
      "implementation - [nmod:of] - records\n",
      "1 2 1624\n",
      "these patient record contain valuable medical information include patient information , diagnosis , treatment method , and eventual patient outcome .\n",
      "records - [det] - These\n",
      "records - [compound] - patient\n",
      "contain - [nsubj] - records\n",
      "2 8 1624\n",
      "it be important to analyze pattern within these record in order to more efficiently treat individual .\n",
      "records - [case] - within\n",
      "records - [det] - these\n",
      "patterns - [nmod:within] - records\n",
      "5 13 1624\n",
      "in we research , we partition graph from term gather from electronic health record .\n",
      "records - [case] - from\n",
      "records - [amod] - electronic\n",
      "records - [compound] - health\n",
      "gathered - [nmod:from] - records\n",
      "#################### ('care', 68.06) ####################\n",
      "0 9 489\n",
      "as we begin to leverage Big Data in health care setting and particularly in assess patient-reported outcome , there be a need for novel analytic to address unique challenge .\n",
      "settings - [compound] - care\n",
      "0 10 115\n",
      "purpose as we begin to leverage Big Data in health care setting and particularly in assess patient-reported outcome , there be a need for novel analytic to address unique challenge .\n",
      "settings - [compound] - care\n",
      "0 23 1566\n",
      "the expand clinical information provide by the advent of electronic medical record offer a exciting opportunity to substantially improve the quality of health care .\n",
      "care - [case] - of\n",
      "care - [compound] - health\n",
      "quality - [nmod:of] - care\n",
      "4 15 1566\n",
      "in addition , we model have the potential to improve the quality of over-all patient care in practice by predict the most likely set of clinical observation at a arbitrary point in the future .\n",
      "care - [case] - of\n",
      "care - [amod] - over-all\n",
      "care - [compound] - patient\n",
      "quality - [nmod:of] - care\n",
      "0 13 1624\n",
      "the recent year have see a surge in the implementation of electronic health care record .\n",
      "records - [compound] - care\n",
      "#################### ('friend', 47.64) ####################\n",
      "8 31 115\n",
      "six month after the surgery , they be replace by goal on regain a sense of normalcy , to resume work , to enjoy life more fully , and to appreciate friend and family more .\n",
      "appreciate - [dobj] - friends\n",
      "friends - [cc] - and\n",
      "friends - [conj:and] - family\n",
      "#################### ('healthcare', 42.31) ####################\n",
      "0 6 1112\n",
      "information and communication technology have enable healthcare institution to accumulate large amount of healthcare datum that include diagnosis , medication , and additional contextual information such as patient demographic .\n",
      "institutions - [compound] - healthcare\n",
      "0 13 1112\n",
      "information and communication technology have enable healthcare institution to accumulate large amount of healthcare datum that include diagnosis , medication , and additional contextual information such as patient demographic .\n",
      "data - [compound] - healthcare\n",
      "1 7 1112\n",
      "to gain a better understanding of big healthcare datum and to develop better data-driven clinical decision support system , we propose a novel multiple - channel latent dirichlet allocation ( mclda ) approach for modeling diagnosis , medication , and contextual information in healthcare datum .\n",
      "data - [compound] - healthcare\n",
      "1 43 1112\n",
      "to gain a better understanding of big healthcare datum and to develop better data-driven clinical decision support system , we propose a novel multiple - channel latent dirichlet allocation ( mclda ) approach for modeling diagnosis , medication , and contextual information in healthcare datum .\n",
      "data - [compound] - healthcare\n",
      "3 9 1112\n",
      "use a real-world research testb that include one million healthcare insurance claim record , we investigate the utility of MCLDA .\n",
      "records - [compound] - healthcare\n",
      "8 9 1112\n",
      "thus , mclda represent a promising approach to modeling healthcare datum for clinical decision support .\n",
      "data - [compound] - healthcare\n",
      "0 1 1129\n",
      "in healthcare organizational setting , the design of a clinical pathway ( cp ) be challenge since patient follow a particular pathway may have not only one single first-diagnosis but also several typical comorbidity , and thus it require different discipline involve to put together they partial knowledge about the overall pathway .\n",
      "settings - [compound] - healthcare\n",
      "#################### ('cancer', 39.36) ####################\n",
      "4 29 489\n",
      "we aim to apply LDA to interview datum collect as part of a prospective , longitudinal study of qol in patient undergo radical cystectomy and urinary diversion for bladder cancer .\n",
      "cancer - [case] - for\n",
      "cancer - [compound] - bladder\n",
      "undergoing - [nmod:for] - cancer\n",
      "5 14 489\n",
      "lda show that , prior to surgery , patient ' priority be primarily in cancer surgery and recovery .\n",
      "surgery - [compound] - cancer\n",
      "3 31 115\n",
      "method LDA be apply to interview datum collect as part of a prospective , longitudinal study of qol in n = 211 patient undergo radical cystectomy and urinary diversion for bladder cancer .\n",
      "cancer - [case] - for\n",
      "cancer - [compound] - bladder\n",
      "undergoing - [nmod:for] - cancer\n",
      "7 10 115\n",
      "prior to surgery , patient ' priority be primarily in cancer surgery and recovery .\n",
      "surgery - [compound] - cancer\n",
      "9 24 115\n",
      "LDA model parameter show change priority , e.g. , immediate concern on surgery and resume employment decrease post-surgery and be replace by concern over cancer recurrence and a desire to remain healthy and strong .\n",
      "recurrence - [compound] - cancer\n",
      "10 47 174\n",
      "in discussion regard as treatment , most topic involve biologic , and most subtheme involve side effect ( e.g. , fatigue , allergic reaction ) , biologic treatment attribute ( e.g. , dosing , frequency ) , and concern about use of biologic ( e.g. , increase cancer risk ) .\n",
      "risk - [compound] - cancer\n",
      "#################### ('code', 36.28) ####################\n",
      "1 5 489\n",
      "one such challenge be in code transcribe interview datum , typically free-text entry of statement make by interviewee during face-to-face interview .\n",
      "ROOT - [ROOT] - coding\n",
      "coding - [nsubj] - challenge\n",
      "coding - [cop] - is\n",
      "coding - [mark] - in\n",
      "coding - [dobj] - data\n",
      "coding - [punct] - .\n",
      "7 25 489\n",
      "novel analytic such as lda offer the possibility of summarize personal goal in real time without the need for conventional fixed-length measure and qualitative datum code .\n",
      "data - [acl] - coding\n",
      "1 5 115\n",
      "one such challenge be in code transcribe interview datum , typically free-text entry of statement make during a face-to-face interview .\n",
      "ROOT - [ROOT] - coding\n",
      "coding - [nsubj] - challenge\n",
      "coding - [cop] - is\n",
      "coding - [mark] - in\n",
      "coding - [dobj] - data\n",
      "coding - [punct] - .\n",
      "10 26 115\n",
      "conclusion novel Big Data analytic such as lda offer the possibility of summarize personal goal without the need for conventional fixed-length measure and resource-intensive qualitative datum code .\n",
      "data - [acl] - coding\n",
      "2 8 1101\n",
      "a medical record contain diagnostic information ( diagnosis code ) , procedure perform ( procedure code ) and admission detail .\n",
      "codes - [punct] - -LRB-\n",
      "codes - [compound] - diagnosis\n",
      "information - [appos] - codes\n",
      "codes - [punct] - -RRB-\n",
      "2 15 1101\n",
      "a medical record contain diagnostic information ( diagnosis code ) , procedure perform ( procedure code ) and admission detail .\n",
      "codes - [punct] - -LRB-\n",
      "codes - [compound] - procedure\n",
      "performed - [appos] - codes\n",
      "codes - [punct] - -RRB-\n",
      "3 37 1101\n",
      "traditional topic model , such as latent dirichlet allocation ( lda ) and hierarchical dirichlet process ( hdp ) , can be employ to discover disease topic from emr datum by treat patient as document and diagnosis code as word .\n",
      "codes - [compound] - diagnosis\n",
      "treating - [nmod:as] - codes\n",
      "documents - [conj:and] - codes\n",
      "6 8 1101\n",
      "we be motivate by the fact that diagnosis code be connect in the form of icd-10 tree structure which present semantic relationship between code .\n",
      "codes - [compound] - diagnosis\n",
      "connected - [nsubjpass] - codes\n",
      "6 23 1101\n",
      "we be motivate by the fact that diagnosis code be connect in the form of icd-10 tree structure which present semantic relationship between code .\n",
      "codes - [case] - between\n",
      "relationships - [nmod:between] - codes\n",
      "9 4 1101\n",
      "furthermore , since procedure code be often correlate with diagnosis code , we develop the correspondence wddcrf ( corr-wddcrf ) to explore conditional relationship of procedure code for a give disease pattern .\n",
      "codes - [compound] - procedure\n",
      "correlated - [nsubjpass] - codes\n",
      "9 10 1101\n",
      "furthermore , since procedure code be often correlate with diagnosis code , we develop the correspondence wddcrf ( corr-wddcrf ) to explore conditional relationship of procedure code for a give disease pattern .\n",
      "codes - [case] - with\n",
      "codes - [compound] - diagnosis\n",
      "correlated - [nmod:with] - codes\n",
      "9 26 1101\n",
      "furthermore , since procedure code be often correlate with diagnosis code , we develop the correspondence wddcrf ( corr-wddcrf ) to explore conditional relationship of procedure code for a give disease pattern .\n",
      "codes - [case] - of\n",
      "codes - [compound] - procedure\n",
      "relationships - [nmod:of] - codes\n",
      "14 7 1101\n",
      "beside these , the prediction for procedure code base on the corr-wddcrf also show considerable accuracy .\n",
      "codes - [case] - for\n",
      "codes - [compound] - procedure\n",
      "prediction - [nmod:for] - codes\n",
      "4 29 80\n",
      "topic feature from unstructured datum and feature from structured datum be compare between veteran with ( n = 1861 ) and without ( n = 9305 ) icd-9 dementia code .\n",
      "codes - [case] - without\n",
      "codes - [compound] - ICD-9\n",
      "codes - [compound] - dementia\n",
      "Veterans - [nmod:without] - codes\n",
      "5 35 80\n",
      "a logistic regression model be use to develop dementia prediction score , and manual review be conduct to validate the machine-learning results.resultsa total of 853 feature be identify ( 290 topic , 174 non-dementia icd code , 159 CPT code , 59 medication , and 171 note type ) for the development of logistic regression prediction score .\n",
      "codes - [nummod] - 174\n",
      "codes - [amod] - non-dementia\n",
      "codes - [compound] - ICD\n",
      "topics - [appos] - codes\n",
      "5 39 80\n",
      "a logistic regression model be use to develop dementia prediction score , and manual review be conduct to validate the machine-learning results.resultsa total of 853 feature be identify ( 290 topic , 174 non-dementia icd code , 159 CPT code , 59 medication , and 171 note type ) for the development of logistic regression prediction score .\n",
      "codes - [nummod] - 159\n",
      "codes - [compound] - CPT\n",
      "topics - [appos] - codes\n",
      "6 12 80\n",
      "these score be validate in a subset of veteran without icd-9 dementia code ( n = 120 ) by expert in dementia who perform manual record review and achieve a high level of inter-rater agreement .\n",
      "codes - [case] - without\n",
      "codes - [compound] - ICD-9\n",
      "codes - [compound] - dementia\n",
      "validated - [nmod:without] - codes\n",
      "codes - [dep] - n\n",
      "codes - [nmod:by] - experts\n",
      "8 8 80\n",
      "ConclusionsDementia be underdiagnosed , and thus , icd code alone can not serve as a gold standard for diagnosis .\n",
      "codes - [compound] - ICD\n",
      "serve - [nsubj] - codes\n",
      "codes - [advmod] - alone\n",
      "9 12 80\n",
      "however , this study suggest that imperfect datum ( e.g. , icd code in combination with other ehr feature ) can serve as a silver standard to develop a risk model , apply that model to patient without dementia code , and then select a case-detection threshold .\n",
      "codes - [compound] - ICD\n",
      "serve - [nsubj] - codes\n",
      "apply - [nsubj] - codes\n",
      "select - [nsubj] - codes\n",
      "codes - [nmod:in] - combination\n",
      "codes - [punct] - -RRB-\n",
      "9 39 80\n",
      "however , this study suggest that imperfect datum ( e.g. , icd code in combination with other ehr feature ) can serve as a silver standard to develop a risk model , apply that model to patient without dementia code , and then select a case-detection threshold .\n",
      "codes - [case] - without\n",
      "codes - [compound] - dementia\n",
      "patients - [nmod:without] - codes\n",
      "1 16 1037\n",
      "the symptom or characteristic of illness course necessary to develop reliable predictor be not available in code billing datum , but may be present in narrative electronic health record ( ehr ) discharge summary .\n",
      "data - [amod] - coded\n",
      "#################### ('data', 32.74) ####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7 2304\n",
      "in this paper , we propose a data mining method , call the Symptom-Herb-Diagnosis topic ( shot ) model , to automatically extract the common relationship among symptom , herb combination and diagnosis from large-scale cm clinical datum .\n",
      "method - [compound] - data\n",
      "4 19 1037\n",
      "the cohort be randomly split to derive a training ( 70 % ) and testing ( 30 % ) data set , and we train separate support vector machine model for baseline clinical feature alone , baseline feature plus common individual word and the above plus topic identify from the 75-topic LDA model .\n",
      "set - [compound] - data\n",
      "7 20 1037\n",
      "by include LDA topic , prediction of readmission , as measure by area under receiver-operating characteristic curve in the testing data set , be improve from baseline ( area under the curve 0.618 ) to baseline + 1000 word ( 0.682 ) to baseline +75 topic ( 0.784 ) .\n",
      "set - [compound] - data\n",
      "1 8 174\n",
      "in this study , we use social media data to examine the knowledge , attitude , and belief of as patient regard biologic therapy .\n",
      "data - [amod] - social\n",
      "data - [compound] - media\n",
      "used - [dobj] - data\n",
      "4 23 174\n",
      "to explore theme within the collection of post in a unsupervised manner , a latent Dirichlet allocation topic model be fit to the data set .\n",
      "set - [compound] - data\n",
      "6 14 174\n",
      "the topic be manually review to identify theme , which be confirm use thematic data analysis .\n",
      "analysis - [compound] - data\n",
      "#################### ('conclusion', 30.77) ####################\n",
      "10 0 115\n",
      "conclusion novel Big Data analytic such as lda offer the possibility of summarize personal goal without the need for conventional fixed-length measure and resource-intensive qualitative datum code .\n",
      "analytics - [compound] - Conclusions\n",
      "10 0 1402\n",
      "conclusion : experimental result reveal that we model achieve competitive performance in risk stratification in comparison with exist supervised approach .\n",
      "ROOT - [ROOT] - Conclusions\n",
      "Conclusions - [punct] - :\n",
      "Conclusions - [appos] - reveal\n",
      "Conclusions - [punct] - .\n",
      "12 0 174\n",
      "conclusion Social media reveal a dynamic range of theme govern as patient ' experience with and choice of biologic agent .\n",
      "media - [compound] - Conclusion\n",
      "15 0 338\n",
      "conclusion : this mixed-methods approach , integrate literature review , data-driven topic discovery , and human annotation , be a effective and rigorous way to develop a physician review topic taxonomy .\n",
      "ROOT - [ROOT] - Conclusions\n",
      "Conclusions - [punct] - :\n",
      "Conclusions - [dep] - way\n",
      "Conclusions - [punct] - .\n",
      "#################### ('physician', 29.99) ####################\n",
      "4 34 1446\n",
      "discover treatment pattern , as actionable knowledge represent the best practice for most patient in most time of they treatment process , form the backbone of cp , and can be exploit to help physician better understand they specialty and learn from previous experience for cp analysis and improvement .\n",
      "help - [dobj] - physicians\n",
      "0 9 1402\n",
      "background and objective : risk stratification aim to provide physician with the accurate assessment of a patient 's clinical risk such that a individualized prevention or management strategy can be develop and deliver .\n",
      "provide - [dobj] - physicians\n",
      "physicians - [nmod:with] - assessment\n",
      "0 3 338\n",
      "background : web-based physician review be invaluable gold mine that merit further investigation .\n",
      "reviews - [compound] - physician\n",
      "1 9 338\n",
      "although many study have explore the text information of physician review , very few have focus on develop a systematic topic taxonomy embed in physician review .\n",
      "reviews - [compound] - physician\n",
      "1 24 338\n",
      "although many study have explore the text information of physician review , very few have focus on develop a systematic topic taxonomy embed in physician review .\n",
      "reviews - [compound] - physician\n",
      "2 5 338\n",
      "the first step toward mining physician review be to determine how the natural structure or dimension be embed in review .\n",
      "reviews - [compound] - physician\n",
      "4 17 338\n",
      "objective : this study aim to develop a hierarchical topic taxonomy to uncover the latent structure of physician review and illustrate its application for mining patient ' interest base on the propose taxonomy and algorithm .\n",
      "reviews - [compound] - physician\n",
      "5 5 338\n",
      "method : datum comprise 122,716 physician review , include review of 8501 doctor from a lead physician review website in China ( haodf.com ) , collect between 2007 and 2015 .\n",
      "reviews - [compound] - physician\n",
      "5 16 338\n",
      "method : datum comprise 122,716 physician review , include review of 8501 doctor from a lead physician review website in China ( haodf.com ) , collect between 2007 and 2015 .\n",
      "website - [compound] - physician\n",
      "6 20 338\n",
      "mixed method , include a literature review , data-driven-based topic discovery , and human annotation be use to develop the physician review topic taxonomy .\n",
      "taxonomy - [compound] - physician\n",
      "15 27 338\n",
      "conclusion : this mixed-methods approach , integrate literature review , data-driven topic discovery , and human annotation , be a effective and rigorous way to develop a physician review topic taxonomy .\n",
      "taxonomy - [compound] - physician\n",
      "#################### ('emr', 25.48) ####################\n",
      "1 19 1566\n",
      "by examine the clinical observation ( such as diagnosis , risk factor , and medication ) mention in longitudinal emr , we can use patient ' medical chronology to automatically predict the progression of they pathology .\n",
      "EMRs - [case] - in\n",
      "EMRs - [amod] - longitudinal\n",
      "mentioned - [nmod:in] - EMRs\n",
      "1 2 1101\n",
      "a hospital emr dataset typically consist of medical record of hospitalize patient .\n",
      "dataset - [compound] - EMR\n",
      "3 28 1101\n",
      "traditional topic model , such as latent dirichlet allocation ( lda ) and hierarchical dirichlet process ( hdp ) , can be employ to discover disease topic from emr datum by treat patient as document and diagnosis code as word .\n",
      "data - [compound] - EMR\n",
      "0 5 627\n",
      "obstetric electronic medical record ( emr ) contain massive amount of medical datum and health information .\n",
      "EMRs - [punct] - -LRB-\n",
      "records - [appos] - EMRs\n",
      "EMRs - [punct] - -RRB-\n",
      "1 8 627\n",
      "the information extraction and diagnosis assistant of obstetric emr be of great significance in improve the fertility level of the population .\n",
      "EMRs - [case] - of\n",
      "EMRs - [amod] - obstetric\n",
      "extraction - [nmod:of] - EMRs\n",
      "2 10 627\n",
      "the admit diagnosis in the first course record of the emr be reason from various source , such as chief complaint , auxiliary examination , and physical examination .\n",
      "EMR - [case] - of\n",
      "EMR - [det] - the\n",
      "record - [nmod:of] - EMR\n",
      "3 17 627\n",
      "this paper treat the diagnosis assistant as a multilabel classification task base on the analysis of obstetric emr .\n",
      "EMRs - [case] - of\n",
      "EMRs - [amod] - obstetric\n",
      "analyses - [nmod:of] - EMRs\n",
      "7 11 627\n",
      "additionally , the method can be use not only for obstetric emr but also for other medical record .\n",
      "EMRs - [cc:preconj] - only\n",
      "EMRs - [case] - for\n",
      "EMRs - [amod] - obstetric\n",
      "used - [nmod:for] - EMRs\n",
      "1 19 1446\n",
      "recently , with the rapid development of hospital information system , a large volume of electronic medical record ( emr ) have be produce , which provide a comprehensive source for cp analysis .\n",
      "EMRs - [punct] - -LRB-\n",
      "records - [appos] - EMRs\n",
      "EMRs - [punct] - -RRB-\n",
      "2 14 1446\n",
      "in this paper , we be concern with the problem of utilize the heterogeneous emr to assist cp analysis and improvement .\n",
      "EMRs - [det] - the\n",
      "EMRs - [amod] - heterogeneous\n",
      "utilizing - [dobj] - EMRs\n",
      "3 23 1446\n",
      "more specifically , we develop a probabilistic topic model to link patient feature and treatment behavior together to mine treatment pattern hide in emr .\n",
      "EMRs - [case] - in\n",
      "hidden - [nmod:in] - EMRs\n",
      "5 8 1446\n",
      "experimental result on a real collection of 985 emr collect from a chinese hospital show that the propose approach can effectively identify meaningful treatment pattern from emr .\n",
      "EMRs - [case] - of\n",
      "EMRs - [compound] - 985\n",
      "collection - [nmod:of] - EMRs\n",
      "EMRs - [acl] - collected\n",
      "5 26 1446\n",
      "experimental result on a real collection of 985 emr collect from a chinese hospital show that the propose approach can effectively identify meaningful treatment pattern from emr .\n",
      "EMRs - [case] - from\n",
      "patterns - [nmod:from] - EMRs\n",
      "#################### ('ehr', 25.13) ####################\n",
      "3 31 80\n",
      "this study seek to identify case of undiagnosed dementia by develop and validate a weakly supervise machine-learning approach that incorporate the analysis of both structured and unstructured electronic health record ( ehr ) data.methodsa topic modeling approach that include latent Dirichlet allocation , stable topic extraction , and random sampling be apply to VHA ehr .\n",
      "EHR - [punct] - -LRB-\n",
      "record - [appos] - EHR\n",
      "EHR - [punct] - -RRB-\n",
      "3 54 80\n",
      "this study seek to identify case of undiagnosed dementia by develop and validate a weakly supervise machine-learning approach that incorporate the analysis of both structured and unstructured electronic health record ( ehr ) data.methodsa topic modeling approach that include latent Dirichlet allocation , stable topic extraction , and random sampling be apply to VHA ehr .\n",
      "EHRs - [case] - to\n",
      "EHRs - [compound] - VHA\n",
      "applied - [nmod:to] - EHRs\n",
      "9 17 80\n",
      "however , this study suggest that imperfect datum ( e.g. , icd code in combination with other ehr feature ) can serve as a silver standard to develop a risk model , apply that model to patient without dementia code , and then select a case-detection threshold .\n",
      "features - [compound] - EHR\n",
      "10 13 80\n",
      "the study be one of the first to utilize both structured and unstructured ehr to develop risk score for the diagnosis of dementia .\n",
      "EHRs - [amod] - structured\n",
      "EHRs - [amod] - unstructured\n",
      "utilize - [dobj] - EHRs\n",
      "1 30 1037\n",
      "the symptom or characteristic of illness course necessary to develop reliable predictor be not available in code billing datum , but may be present in narrative electronic health record ( ehr ) discharge summary .\n",
      "EHR - [punct] - -LRB-\n",
      "record - [appos] - EHR\n",
      "EHR - [punct] - -RRB-\n",
      "9 12 1037\n",
      "topic modeling and related approach offer the potential to improve prediction use ehr , if generalizability can be establish in other clinical cohort .\n",
      "using - [dobj] - EHRs\n",
      "2 26 1402\n",
      "to this end , in this paper , we propose a new approach for risk stratification by explore a large volume of electronic health record ( ehr ) in a unsupervised fashion .\n",
      "EHRs - [punct] - -LRB-\n",
      "records - [appos] - EHRs\n",
      "EHRs - [punct] - -RRB-\n",
      "4 25 1402\n",
      "the propose PRSM recognize a patient clinical state as a probabilistic combination of latent sub-profile , and generate sub-profile-specific risk tier of patient from they ehr in a fully unsupervised fashion .\n",
      "EHRs - [case] - from\n",
      "EHRs - [nmod:poss] - their\n",
      "patients - [nmod:from] - EHRs\n",
      "13 19 1402\n",
      "we hypothesize that the propose framework can readily meet the demand for risk stratification from a large volume of ehr in a open-ended fashion .\n",
      "EHRs - [case] - of\n",
      "volume - [nmod:of] - EHRs\n",
      "#################### ('doctor', 24.57) ####################\n",
      "5 12 338\n",
      "method : datum comprise 122,716 physician review , include review of 8501 doctor from a lead physician review website in China ( haodf.com ) , collect between 2007 and 2015 .\n",
      "doctors - [case] - of\n",
      "doctors - [nummod] - 8501\n",
      "reviews - [nmod:of] - doctors\n"
     ]
    }
   ],
   "source": [
    "t_idx = 1\n",
    "for term in top_terms[t_idx]:\n",
    "    print(\"#\"*20, term, \"#\"*20)\n",
    "    for top_doc in top_docs[t_idx]:\n",
    "        _idx = top_doc[0]\n",
    "        if type(parse[_idx]) is str:\n",
    "            print(_idx, \"parse\", \"err\")\n",
    "            continue\n",
    "        sents = relation.convert_parse2lemma_sents(parse[_idx])\n",
    "        for sent_idx,sent in enumerate(sents):\n",
    "            topic_word_idxs = relation.get_word_idx(term[0], sent)\n",
    "            for i in topic_word_idxs:\n",
    "                print(sent_idx, i, _idx)\n",
    "                print(\" \".join(relation.convert_parse2lemma_sents(parse[_idx])[sent_idx]).strip())\n",
    "                rs = relation.extract_word_relation_from_sent(i, parse[_idx][\"sentences\"][sent_idx][\"enhancedPlusPlusDependencies\"])\n",
    "                for r in rs:\n",
    "                    print(relation.convert_relation2str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'hospital', 'emr', 'dataset', 'typically', 'consist', 'of', 'medical', 'record', 'of', 'hospitalize', 'patient', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dep': 'ROOT',\n",
       "  'governor': 0,\n",
       "  'governorGloss': 'ROOT',\n",
       "  'dependent': 6,\n",
       "  'dependentGloss': 'consists'},\n",
       " {'dep': 'nsubj',\n",
       "  'governor': 6,\n",
       "  'governorGloss': 'consists',\n",
       "  'dependent': 4,\n",
       "  'dependentGloss': 'dataset'},\n",
       " {'dep': 'advmod',\n",
       "  'governor': 6,\n",
       "  'governorGloss': 'consists',\n",
       "  'dependent': 5,\n",
       "  'dependentGloss': 'typically'},\n",
       " {'dep': 'nmod:of',\n",
       "  'governor': 6,\n",
       "  'governorGloss': 'consists',\n",
       "  'dependent': 9,\n",
       "  'dependentGloss': 'records'},\n",
       " {'dep': 'punct',\n",
       "  'governor': 6,\n",
       "  'governorGloss': 'consists',\n",
       "  'dependent': 13,\n",
       "  'dependentGloss': '.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_idx = 1101\n",
    "sents = relation.convert_parse2lemma_sents(parse[_idx])\n",
    "idxs = relation.get_word_idx(\"consist\", sents[1])\n",
    "print(sents[1])\n",
    "sent_tokens = parse[_idx][\"sentences\"][1][\"tokens\"]\n",
    "sent_deps = parse[_idx][\"sentences\"][1][\"enhancedPlusPlusDependencies\"]\n",
    "relation.extract_word_relation_from_sent(idxs[0], parse[_idx][\"sentences\"][1][\"enhancedPlusPlusDependencies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07 2 489 5\n",
      "lda show that , prior to surgery , patient ' priority be primarily in cancer surgery and recovery .\n",
      "LDA showed that, prior to surgery, patients' priorities were primarily in cancer surgery and recovery.\n",
      "[(0,), (1,), None]\n",
      "========================================\n",
      "1.07 2 489 4\n",
      "we aim to apply LDA to interview datum collect as part of a prospective , longitudinal study of qol in patient undergo radical cystectomy and urinary diversion for bladder cancer .\n",
      "We aim to apply LDA to interview data collected as part of a prospective, longitudinal study of QOL in patients undergoing radical cystectomy and urinary diversion for bladder cancer.\n",
      "[(0,), (1,), None]\n",
      "========================================\n",
      "1.0 1 489 3\n",
      "latent Dirichlet allocation -lrb- lda -rrb- may offer statistical rigor in summarize patient ' concern and cope strategy in a life-threatening illness .\n",
      "Latent Dirichlet Allocation (LDA) may offer statistical rigor in summarizing patients' concerns and coping strategies in a life-threatening illness.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'clause_predicate_idx' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9a7449591ba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sent token differ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mtriples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_triples_from_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_deps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtriple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/e/毕业论文_ued/code/relation.py\u001b[0m in \u001b[0;36mextract_triples_from_sent\u001b[0;34m(sent_deps, sent_tokens)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madvcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0masubjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mapredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclause_predicate_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0maobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mclause_predicate_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEPENDENT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# 从句谓词句子中索引\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'clause_predicate_idx' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for top_doc in top_docs[t_idx]:\n",
    "    _idx = top_doc[0]\n",
    "    if type(parse[_idx]) is str:\n",
    "        print(_idx, \"parse\", \"err\")\n",
    "        continue\n",
    "    sents = relation.convert_parse2lemma_sents(parse[_idx])\n",
    "    sort_idxs, importance, counts = relation.extract_important_sents(sents, [x[0] for x in top_terms[t_idx]], [x[1] for x in top_terms[t_idx]])\n",
    "    for i in sort_idxs:\n",
    "        if importance[i]>0:\n",
    "            print(round(importance[i], 2), counts[i], _idx, i)\n",
    "            sent_tokens = parse[_idx][\"sentences\"][i][\"tokens\"]\n",
    "            sent_deps = parse[_idx][\"sentences\"][i][\"enhancedPlusPlusDependencies\"]\n",
    "            print(\" \".join([s[\"lemma\"] for s in sent_tokens]))\n",
    "            sents = sent_tokenize(_raw[_idx])\n",
    "            if len(sents) > i:\n",
    "                print(sents[i])\n",
    "            else:\n",
    "                print(\"sent token differ\")\n",
    "            triples = relation.extract_triples_from_sent(sent_deps, sent_tokens)\n",
    "            for triple in triples:\n",
    "                if None in triple:\n",
    "                    print(triple)\n",
    "                    continue\n",
    "                s = [sent_tokens[i][\"originalText\"] for i in triple[0]]\n",
    "                p = [sent_tokens[i][\"originalText\"] for i in triple[1]]\n",
    "                o = [sent_tokens[i][\"originalText\"] for i in triple[2]]\n",
    "                print(\"{}-{}-{}\".format(s,p,o))\n",
    "            print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = relation.get_phrases_by_pattern(parse)\n",
    "sorted(dict(Counter([\" \".join(x) for x in ps])).items(), key=lambda x:x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lda362",
   "language": "python",
   "name": "lda362"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
